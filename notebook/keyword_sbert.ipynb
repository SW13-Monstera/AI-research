{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a697ff14",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "##%% md\n",
    "## !pip install sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42fd5d5d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name /Users/minjaewon/.cache/torch/sentence_transformers/Huffon_sentence-klue-roberta-base. Creating a new one with MEAN pooling.\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer(\"Huffon/sentence-klue-roberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "device(type='mps')"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.device(\"mps\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "SentenceTransformer(\n  (0): Transformer({'max_seq_length': 512, 'do_lower_case': False}) with Transformer model: RobertaModel \n  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n)"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mps_device = torch.device(\"mps\")\n",
    "model.to(mps_device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ff5f4d9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "device(type='mps', index=0)"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c06601b3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('user_answer.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f4ad0d9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "            problem_id                        problem   assign  \\\n0    recXfKthnQLwWETgb  [네트워크 1] 쿠키와 세션의 차이점을 설명해주세요.     jack   \n1    recXfKthnQLwWETgb  [네트워크 1] 쿠키와 세션의 차이점을 설명해주세요.     jack   \n2    recXfKthnQLwWETgb  [네트워크 1] 쿠키와 세션의 차이점을 설명해주세요.     jack   \n3    recXfKthnQLwWETgb  [네트워크 1] 쿠키와 세션의 차이점을 설명해주세요.     jack   \n4    recXfKthnQLwWETgb  [네트워크 1] 쿠키와 세션의 차이점을 설명해주세요.     jack   \n..                 ...                            ...      ...   \n445  recUcGjT9Xkb7N5pu    [자료구조 3] Queue의 특징을 설명해주세요.  kshired   \n446  recUcGjT9Xkb7N5pu    [자료구조 3] Queue의 특징을 설명해주세요.  kshired   \n447  recUcGjT9Xkb7N5pu    [자료구조 3] Queue의 특징을 설명해주세요.  kshired   \n448  recUcGjT9Xkb7N5pu    [자료구조 3] Queue의 특징을 설명해주세요.  kshired   \n449  recUcGjT9Xkb7N5pu    [자료구조 3] Queue의 특징을 설명해주세요.  kshired   \n\n                                           user_answer  \\\n0    쿠키는 개인 PC에 text로 저장된다. 세션은 접속중인 웹 서버에 Object로 ...   \n1    세션이 쿠키에 비해 보안도 높은 편이나 쿠키를 사용하는 이유는세션은 서버에 저장되고...   \n2    쿠키와 세션의 가장 큰 차이점은 정보가 저장되는 위치입니다. 쿠키는 서버의 자원을 ...   \n3    쿠키는 클라이언트 로컬에 저장되기 때문에 변질되거나 request에서 스니핑 당할 ...   \n4    쿠키도 만료시간이 있지만 파일로 저장되기 때문에 브라우저를 종료해도 계속해서 정보가...   \n..                                                 ...   \n445  데이터가 삽입된 순서대로 삭제되는 선입선출(FIFO, First-In-First-O...   \n446  선입선출(FIFO, First in first out) 방식의 자료구조를 말한다. ...   \n447  큐는 스택 자료구조와 달리 FIFO (First-In First-Out)- 선입 선...   \n448  큐(Queue)는 FIFO(First In First Out) 의 특징을 갖는 자료...   \n449  선입선출(FIFO, First in first out) 방식의 자료구조를 말한다. ...   \n\n                                     scoring_criterion  \\\n0    ['세션이 쿠키보다 보안에 유리하다는 내용 - 1점', '세션이 쿠키보다 속도가 느...   \n1    ['세션이 쿠키보다 보안에 유리하다는 내용 - 1점', '세션이 쿠키보다 속도가 느...   \n2    ['세션이 쿠키보다 보안에 유리하다는 내용 - 1점', '세션이 쿠키보다 속도가 느...   \n3    ['세션이 쿠키보다 보안에 유리하다는 내용 - 1점', '세션이 쿠키보다 속도가 느...   \n4    ['세션이 쿠키보다 보안에 유리하다는 내용 - 1점', '세션이 쿠키보다 속도가 느...   \n..                                                 ...   \n445  ['rear에서 자료의 삽입이 front에서 자료의 삭제가 이루어짐 - 1점', '...   \n446  ['rear에서 자료의 삽입이 front에서 자료의 삭제가 이루어짐 - 1점', '...   \n447  ['rear에서 자료의 삽입이 front에서 자료의 삭제가 이루어짐 - 1점', '...   \n448  ['rear에서 자료의 삽입이 front에서 자료의 삭제가 이루어짐 - 1점', '...   \n449  ['rear에서 자료의 삽입이 front에서 자료의 삭제가 이루어짐 - 1점', '...   \n\n                             correct_scoring_criterion  \\\n0    ['세션이 쿠키보다 속도가 느리다는 내용 - 1점', '저장위치가 쿠키는 클라이언트...   \n1    ['세션이 쿠키보다 보안에 유리하다는 내용 - 1점', '세션이 쿠키보다 속도가 느...   \n2    ['세션이 쿠키보다 보안에 유리하다는 내용 - 1점', '세션이 쿠키보다 속도가 느...   \n3    ['세션이 쿠키보다 보안에 유리하다는 내용 - 1점', '저장위치가 쿠키는 클라이언...   \n4                            ['Lifecycle에 대한 내용 - 1점']   \n..                                                 ...   \n445  ['rear에서 자료의 삽입이 front에서 자료의 삭제가 이루어짐 - 1점', '...   \n446  ['rear에서 자료의 삽입이 front에서 자료의 삭제가 이루어짐 - 1점', '...   \n447  ['rear에서 자료의 삽입이 front에서 자료의 삭제가 이루어짐 - 1점', '...   \n448  ['rear에서 자료의 삽입이 front에서 자료의 삭제가 이루어짐 - 1점', '...   \n449  ['rear에서 자료의 삽입이 front에서 자료의 삭제가 이루어짐 - 1점', '...   \n\n                                     keyword_criterion  \\\n0    ['Lifecycle - 1점', '보안 - 1점', '저장위치 - 2점', '속도...   \n1    ['Lifecycle - 1점', '보안 - 1점', '저장위치 - 2점', '속도...   \n2    ['Lifecycle - 1점', '보안 - 1점', '저장위치 - 2점', '속도...   \n3    ['Lifecycle - 1점', '보안 - 1점', '저장위치 - 2점', '속도...   \n4    ['Lifecycle - 1점', '보안 - 1점', '저장위치 - 2점', '속도...   \n..                                                 ...   \n445  ['시간복잡도 - 1점', 'FIFO - 2점', '삭제(POP) - 1점', '삽...   \n446  ['시간복잡도 - 1점', 'FIFO - 2점', '삭제(POP) - 1점', '삽...   \n447  ['시간복잡도 - 1점', 'FIFO - 2점', '삭제(POP) - 1점', '삽...   \n448  ['시간복잡도 - 1점', 'FIFO - 2점', '삭제(POP) - 1점', '삽...   \n449  ['시간복잡도 - 1점', 'FIFO - 2점', '삭제(POP) - 1점', '삽...   \n\n                             correct_keyword_criterion          annotator  \n0                             ['저장위치 - 2점', '속도 - 1점']  mjw8523@gmail.com  \n1                  ['보안 - 1점', '저장위치 - 2점', '속도 - 1점']  mjw8523@gmail.com  \n2                  ['보안 - 1점', '저장위치 - 2점', '속도 - 1점']  mjw8523@gmail.com  \n3                             ['보안 - 1점', '저장위치 - 2점']  mjw8523@gmail.com  \n4                                   ['Lifecycle - 1점']  mjw8523@gmail.com  \n..                                                 ...                ...  \n445  ['시간복잡도 - 1점', 'FIFO - 2점', '삭제(POP) - 1점', '삽...  mjw8523@gmail.com  \n446     ['FIFO - 2점', '삭제(POP) - 1점', '삽입(PUSH) - 1점']  mjw8523@gmail.com  \n447     ['FIFO - 2점', '삭제(POP) - 1점', '삽입(PUSH) - 1점']  mjw8523@gmail.com  \n448     ['FIFO - 2점', '삭제(POP) - 1점', '삽입(PUSH) - 1점']  mjw8523@gmail.com  \n449     ['FIFO - 2점', '삭제(POP) - 1점', '삽입(PUSH) - 1점']  mjw8523@gmail.com  \n\n[450 rows x 9 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>problem_id</th>\n      <th>problem</th>\n      <th>assign</th>\n      <th>user_answer</th>\n      <th>scoring_criterion</th>\n      <th>correct_scoring_criterion</th>\n      <th>keyword_criterion</th>\n      <th>correct_keyword_criterion</th>\n      <th>annotator</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>recXfKthnQLwWETgb</td>\n      <td>[네트워크 1] 쿠키와 세션의 차이점을 설명해주세요.</td>\n      <td>jack</td>\n      <td>쿠키는 개인 PC에 text로 저장된다. 세션은 접속중인 웹 서버에 Object로 ...</td>\n      <td>['세션이 쿠키보다 보안에 유리하다는 내용 - 1점', '세션이 쿠키보다 속도가 느...</td>\n      <td>['세션이 쿠키보다 속도가 느리다는 내용 - 1점', '저장위치가 쿠키는 클라이언트...</td>\n      <td>['Lifecycle - 1점', '보안 - 1점', '저장위치 - 2점', '속도...</td>\n      <td>['저장위치 - 2점', '속도 - 1점']</td>\n      <td>mjw8523@gmail.com</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>recXfKthnQLwWETgb</td>\n      <td>[네트워크 1] 쿠키와 세션의 차이점을 설명해주세요.</td>\n      <td>jack</td>\n      <td>세션이 쿠키에 비해 보안도 높은 편이나 쿠키를 사용하는 이유는세션은 서버에 저장되고...</td>\n      <td>['세션이 쿠키보다 보안에 유리하다는 내용 - 1점', '세션이 쿠키보다 속도가 느...</td>\n      <td>['세션이 쿠키보다 보안에 유리하다는 내용 - 1점', '세션이 쿠키보다 속도가 느...</td>\n      <td>['Lifecycle - 1점', '보안 - 1점', '저장위치 - 2점', '속도...</td>\n      <td>['보안 - 1점', '저장위치 - 2점', '속도 - 1점']</td>\n      <td>mjw8523@gmail.com</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>recXfKthnQLwWETgb</td>\n      <td>[네트워크 1] 쿠키와 세션의 차이점을 설명해주세요.</td>\n      <td>jack</td>\n      <td>쿠키와 세션의 가장 큰 차이점은 정보가 저장되는 위치입니다. 쿠키는 서버의 자원을 ...</td>\n      <td>['세션이 쿠키보다 보안에 유리하다는 내용 - 1점', '세션이 쿠키보다 속도가 느...</td>\n      <td>['세션이 쿠키보다 보안에 유리하다는 내용 - 1점', '세션이 쿠키보다 속도가 느...</td>\n      <td>['Lifecycle - 1점', '보안 - 1점', '저장위치 - 2점', '속도...</td>\n      <td>['보안 - 1점', '저장위치 - 2점', '속도 - 1점']</td>\n      <td>mjw8523@gmail.com</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>recXfKthnQLwWETgb</td>\n      <td>[네트워크 1] 쿠키와 세션의 차이점을 설명해주세요.</td>\n      <td>jack</td>\n      <td>쿠키는 클라이언트 로컬에 저장되기 때문에 변질되거나 request에서 스니핑 당할 ...</td>\n      <td>['세션이 쿠키보다 보안에 유리하다는 내용 - 1점', '세션이 쿠키보다 속도가 느...</td>\n      <td>['세션이 쿠키보다 보안에 유리하다는 내용 - 1점', '저장위치가 쿠키는 클라이언...</td>\n      <td>['Lifecycle - 1점', '보안 - 1점', '저장위치 - 2점', '속도...</td>\n      <td>['보안 - 1점', '저장위치 - 2점']</td>\n      <td>mjw8523@gmail.com</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>recXfKthnQLwWETgb</td>\n      <td>[네트워크 1] 쿠키와 세션의 차이점을 설명해주세요.</td>\n      <td>jack</td>\n      <td>쿠키도 만료시간이 있지만 파일로 저장되기 때문에 브라우저를 종료해도 계속해서 정보가...</td>\n      <td>['세션이 쿠키보다 보안에 유리하다는 내용 - 1점', '세션이 쿠키보다 속도가 느...</td>\n      <td>['Lifecycle에 대한 내용 - 1점']</td>\n      <td>['Lifecycle - 1점', '보안 - 1점', '저장위치 - 2점', '속도...</td>\n      <td>['Lifecycle - 1점']</td>\n      <td>mjw8523@gmail.com</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>445</th>\n      <td>recUcGjT9Xkb7N5pu</td>\n      <td>[자료구조 3] Queue의 특징을 설명해주세요.</td>\n      <td>kshired</td>\n      <td>데이터가 삽입된 순서대로 삭제되는 선입선출(FIFO, First-In-First-O...</td>\n      <td>['rear에서 자료의 삽입이 front에서 자료의 삭제가 이루어짐 - 1점', '...</td>\n      <td>['rear에서 자료의 삽입이 front에서 자료의 삭제가 이루어짐 - 1점', '...</td>\n      <td>['시간복잡도 - 1점', 'FIFO - 2점', '삭제(POP) - 1점', '삽...</td>\n      <td>['시간복잡도 - 1점', 'FIFO - 2점', '삭제(POP) - 1점', '삽...</td>\n      <td>mjw8523@gmail.com</td>\n    </tr>\n    <tr>\n      <th>446</th>\n      <td>recUcGjT9Xkb7N5pu</td>\n      <td>[자료구조 3] Queue의 특징을 설명해주세요.</td>\n      <td>kshired</td>\n      <td>선입선출(FIFO, First in first out) 방식의 자료구조를 말한다. ...</td>\n      <td>['rear에서 자료의 삽입이 front에서 자료의 삭제가 이루어짐 - 1점', '...</td>\n      <td>['rear에서 자료의 삽입이 front에서 자료의 삭제가 이루어짐 - 1점', '...</td>\n      <td>['시간복잡도 - 1점', 'FIFO - 2점', '삭제(POP) - 1점', '삽...</td>\n      <td>['FIFO - 2점', '삭제(POP) - 1점', '삽입(PUSH) - 1점']</td>\n      <td>mjw8523@gmail.com</td>\n    </tr>\n    <tr>\n      <th>447</th>\n      <td>recUcGjT9Xkb7N5pu</td>\n      <td>[자료구조 3] Queue의 특징을 설명해주세요.</td>\n      <td>kshired</td>\n      <td>큐는 스택 자료구조와 달리 FIFO (First-In First-Out)- 선입 선...</td>\n      <td>['rear에서 자료의 삽입이 front에서 자료의 삭제가 이루어짐 - 1점', '...</td>\n      <td>['rear에서 자료의 삽입이 front에서 자료의 삭제가 이루어짐 - 1점', '...</td>\n      <td>['시간복잡도 - 1점', 'FIFO - 2점', '삭제(POP) - 1점', '삽...</td>\n      <td>['FIFO - 2점', '삭제(POP) - 1점', '삽입(PUSH) - 1점']</td>\n      <td>mjw8523@gmail.com</td>\n    </tr>\n    <tr>\n      <th>448</th>\n      <td>recUcGjT9Xkb7N5pu</td>\n      <td>[자료구조 3] Queue의 특징을 설명해주세요.</td>\n      <td>kshired</td>\n      <td>큐(Queue)는 FIFO(First In First Out) 의 특징을 갖는 자료...</td>\n      <td>['rear에서 자료의 삽입이 front에서 자료의 삭제가 이루어짐 - 1점', '...</td>\n      <td>['rear에서 자료의 삽입이 front에서 자료의 삭제가 이루어짐 - 1점', '...</td>\n      <td>['시간복잡도 - 1점', 'FIFO - 2점', '삭제(POP) - 1점', '삽...</td>\n      <td>['FIFO - 2점', '삭제(POP) - 1점', '삽입(PUSH) - 1점']</td>\n      <td>mjw8523@gmail.com</td>\n    </tr>\n    <tr>\n      <th>449</th>\n      <td>recUcGjT9Xkb7N5pu</td>\n      <td>[자료구조 3] Queue의 특징을 설명해주세요.</td>\n      <td>kshired</td>\n      <td>선입선출(FIFO, First in first out) 방식의 자료구조를 말한다. ...</td>\n      <td>['rear에서 자료의 삽입이 front에서 자료의 삭제가 이루어짐 - 1점', '...</td>\n      <td>['rear에서 자료의 삽입이 front에서 자료의 삭제가 이루어짐 - 1점', '...</td>\n      <td>['시간복잡도 - 1점', 'FIFO - 2점', '삭제(POP) - 1점', '삽...</td>\n      <td>['FIFO - 2점', '삭제(POP) - 1점', '삽입(PUSH) - 1점']</td>\n      <td>mjw8523@gmail.com</td>\n    </tr>\n  </tbody>\n</table>\n<p>450 rows × 9 columns</p>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7ff1400",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "problem_id                                                   recXfKthnQLwWETgb\nproblem                                          [네트워크 1] 쿠키와 세션의 차이점을 설명해주세요.\nassign                                                                    jack\nuser_answer                  쿠키는 개인 PC에 text로 저장된다. 세션은 접속중인 웹 서버에 Object로 ...\nscoring_criterion            ['세션이 쿠키보다 보안에 유리하다는 내용 - 1점', '세션이 쿠키보다 속도가 느...\ncorrect_scoring_criterion    ['세션이 쿠키보다 속도가 느리다는 내용 - 1점', '저장위치가 쿠키는 클라이언트...\nkeyword_criterion            ['Lifecycle - 1점', '보안 - 1점', '저장위치 - 2점', '속도...\ncorrect_keyword_criterion                             ['저장위치 - 2점', '속도 - 1점']\nannotator                                                    mjw8523@gmail.com\nName: 0, dtype: object"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f0503910",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre data size : 450\n",
      "after data size : 449\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# NAN data 제거\n",
    "print(f\"pre data size : {len(df)}\")\n",
    "df['user_answer'] = df['user_answer'].str.strip().str.replace(\"\\n\", \"\").str.replace(\"\\xa0\", \"\").str.replace(\"  \", \" \")\n",
    "df['user_answer'].replace('', np.nan, inplace=True)\n",
    "df.dropna(axis=0, subset=['user_answer'], inplace=True)  # 빈 답변 제거\n",
    "print(f\"after data size : {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1653db86",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "가장 긴 답변 488ch:\n",
      "\t 각 행마다 행을 식별할 수 있도록 전부 다른 값이 저장된 열을 찾으셨다면, 그 열을 가지고 기본 키를 만들 수 있습니다. 다시 한번 강조하자면, 기본 키는 테이블 내의 각 행을 고유하게 하는 열입니다. 고로, 기본 키는 모든 행이 고유한 값을 가지고 있는지 혹은 값이 비어있는 행이 있는지 확인할 수 있도록 합니다. 예를 들어, 여러분이 이미 어떤 열에 존재하는 값을 새로운 행을 만들어서 추가하고자 한다면, 이는 기본 키에 의해서 생성이 제한됩니다.또한, 기본 키는 NULL 값을 받아들이지 않습니다. 즉, 기본 키 열에는 NULL 값이 존재할 수 없습니다. 미국 시민의 정보를 저장하고 있는 테이블인 citizen 예시가 기억나십니까? 만약 social_security_number 열에 NULL 값이 포함된 행을 추가하고자 한다면, 이는 기본 키에 의해서 제지 당합니다. 다시 말해서, 기본 키는 기본 키가 되는 열의 행 값이 고유하고 비어있지 않도록 만들어 줍니다.\n",
      "가장 짧은 답변 13ch:\n",
      "\t 원자성, 일관성이 있다.\n"
     ]
    }
   ],
   "source": [
    "min_len = min(map(len, df['user_answer']))\n",
    "max_len = max(map(len, df['user_answer']))\n",
    "\n",
    "for i, data in df.iterrows():\n",
    "    if len(data['user_answer']) == min_len:\n",
    "        print(f\"가장 짧은 답변 {min_len}ch:\\n\\t {data['user_answer']}\")\n",
    "    elif len(data['user_answer']) == max_len:\n",
    "        print(f\"가장 긴 답변 {max_len}ch:\\n\\t {data['user_answer']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da52c83",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### pip install konlpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d4203d82",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt\n",
    "okt = Okt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d7c1370",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import List\n",
    "\n",
    "@dataclass\n",
    "class Problem:\n",
    "    subject: str  # 문제별\n",
    "    keywords: List[str]  # 문제별\n",
    "    keywords_score: List[int]  # 문제별\n",
    "    keywords_embedding : List[np.ndarray]  # 문제별\n",
    "    user_answers: List[str]  # 유저별\n",
    "    user_correct_keywords: List[List[str]]  # 유저별\n",
    "    ground_truths: List[List[int]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d9871d61",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "problem_id                                                   recXfKthnQLwWETgb\nproblem                                          [네트워크 1] 쿠키와 세션의 차이점을 설명해주세요.\nassign                                                                    jack\nuser_answer                  쿠키는 개인 PC에 text로 저장된다. 세션은 접속중인 웹 서버에 Object로 ...\nscoring_criterion            ['세션이 쿠키보다 보안에 유리하다는 내용 - 1점', '세션이 쿠키보다 속도가 느...\ncorrect_scoring_criterion    ['세션이 쿠키보다 속도가 느리다는 내용 - 1점', '저장위치가 쿠키는 클라이언트...\nkeyword_criterion            ['Lifecycle - 1점', '보안 - 1점', '저장위치 - 2점', '속도...\ncorrect_keyword_criterion                             ['저장위치 - 2점', '속도 - 1점']\nannotator                                                    mjw8523@gmail.com\nName: 0, dtype: object"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e9f2a2b7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset = {}\n",
    "# criterion parsing\n",
    "for i, data in df.iterrows():\n",
    "    problem_id = data['problem_id']\n",
    "    if problem_id not in dataset:\n",
    "        keywords = []\n",
    "        keywords_score = []\n",
    "\n",
    "        for criterion in eval(data['keyword_criterion']):\n",
    "            keyword, score = map(str.strip, criterion.split('-'))\n",
    "            score = float(score.split(\"점\")[0])\n",
    "            keywords.append(keyword)\n",
    "            keywords_score.append(score)\n",
    "        keywords_embedding = model.encode(keywords)\n",
    "\n",
    "        dataset[problem_id] = Problem(\n",
    "            subject=data['problem'],\n",
    "            keywords=keywords,\n",
    "            keywords_score=keywords_score,\n",
    "            keywords_embedding=keywords_embedding,\n",
    "            user_answers=[],\n",
    "            user_correct_keywords=[],\n",
    "            ground_truths=[],\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4718df4e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "problem : [데이터베이스 1] Primary key가 무엇인지 설명해주세요.\n",
      "keywords : ['최소성', '대표성', '유일성', '불변성', '식별자']\n",
      "keywords_score : [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "keyword embedding shape :(5, 768)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "problem_id = random.choice(list(dataset.keys()))\n",
    "print(f\"problem : {dataset[problem_id].subject}\")\n",
    "print(f\"keywords : {dataset[problem_id].keywords}\")\n",
    "print(f\"keywords_score : {dataset[problem_id].keywords_score}\")\n",
    "print(f\"keyword embedding shape :{dataset[problem_id].keywords_embedding.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8511c228",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for i, data in df.iterrows():\n",
    "    problem = dataset[data['problem_id']]\n",
    "    user_answer = data['user_answer']\n",
    "    user_correct_keyword = [criterion.split('-')[0].rstrip() for criterion in eval(data['correct_keyword_criterion'])]\n",
    "    ground_truth = [1 if keyword in user_correct_keyword else 0 for keyword in problem.keywords]\n",
    "    problem.user_correct_keywords.append(user_correct_keyword)\n",
    "    problem.user_answers.append(user_answer)\n",
    "    problem.ground_truths.append(ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5e71d565",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문제       : [자료구조 3] Queue의 특징을 설명해주세요.\n",
      "유저 답변   : 화장실에서 줄서서 기다리고 처리하는 형태의 자료구조로 한 방향에서는 삽입연산이, 반대편에서는 삭제연산이 이루어지는 자료구조이다. 스택과 마찬가지로 선형 자료구조이다. 한쪽 방향에서 삽입이, 반대편에서 삭제가 이루어지기 때문에 먼저 삽입된 데이터가 먼저 삭제되는 선입선출(FIFO) 구조를 가진다. 너비 우선 탐색(BFS) 구현에 사용된다.\n",
      "정답 키워드 : ['FIFO', '삭제(POP)', '삽입(PUSH)']\n",
      "후보 키워드 : ['시간복잡도', 'FIFO', '삭제(POP)', '삽입(PUSH)']\n",
      "정답 라벨  : [0, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "print(f\"문제       : {problem.subject}\")\n",
    "print(f\"유저 답변   : {problem.user_answers[0]}\")\n",
    "print(f\"정답 키워드 : {problem.user_correct_keywords[0]}\")\n",
    "print(f\"후보 키워드 : {problem.keywords}\")\n",
    "print(f\"정답 라벨  : {problem.ground_truths[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "50b30dc2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 하나라도 출력되면 라벨링을 잘못 파싱한 것\n",
    "for problem_id in dataset:\n",
    "    problem = dataset[problem_id]\n",
    "    for gt, correct_keyword in zip(problem.ground_truths, problem.user_correct_keywords):\n",
    "        ground_truth = []\n",
    "        for i, flag in enumerate(gt):\n",
    "            if flag:\n",
    "                ground_truth.append(problem.keywords[i])\n",
    "        if not ground_truth == correct_keyword:\n",
    "            print(ground_truth, correct_keyword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cedd77c6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[네트워크 1] 쿠키와 세션의 차이점을 설명해주세요.\n",
      "45개의 유저 답변\n",
      "45개의 유저의 답변별 키워드 라벨링\n",
      "[네트워크 2] HTTP 메서드의 멱등성에 대해서 설명해주세요.\n",
      "45개의 유저 답변\n",
      "45개의 유저의 답변별 키워드 라벨링\n",
      "[자료구조 1] Array의 특징을 설명해주세요.\n",
      "45개의 유저 답변\n",
      "45개의 유저의 답변별 키워드 라벨링\n",
      "[데이터베이스 2] Transaction의 네가지 특성을 설명해주세요.\n",
      "45개의 유저 답변\n",
      "45개의 유저의 답변별 키워드 라벨링\n",
      "[운영체제 1] Deadlock의 발생조건 네가지를 간단히 설명해주세요.\n",
      "45개의 유저 답변\n",
      "45개의 유저의 답변별 키워드 라벨링\n",
      "[데이터베이스 1] Primary key가 무엇인지 설명해주세요.\n",
      "45개의 유저 답변\n",
      "45개의 유저의 답변별 키워드 라벨링\n",
      "[운영체제 2] 프로세스와 스레드의 차이점을 설명해주세요.\n",
      "45개의 유저 답변\n",
      "45개의 유저의 답변별 키워드 라벨링\n",
      "[데이터베이스 3] DB Index를 어떤 특징을 가진 column에 사용하면 좋을지 설명해주세요.\n",
      "45개의 유저 답변\n",
      "45개의 유저의 답변별 키워드 라벨링\n",
      "[자료구조 2] Stack의 특징을 설명해주세요.\n",
      "44개의 유저 답변\n",
      "44개의 유저의 답변별 키워드 라벨링\n",
      "[자료구조 3] Queue의 특징을 설명해주세요.\n",
      "45개의 유저 답변\n",
      "45개의 유저의 답변별 키워드 라벨링\n"
     ]
    }
   ],
   "source": [
    "for problem_id in dataset:\n",
    "    print(f\"{dataset[problem_id].subject}\")\n",
    "    print(f\"{len(dataset[problem_id].user_answers)}개의 유저 답변\")\n",
    "    print(f\"{len(dataset[problem_id].user_correct_keywords)}개의 유저의 답변별 키워드 라벨링\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "84f96564",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['관성', '트랜잭션', '작업', '처리', '결과', '항상', '관성', '독립성', '둘', '이상']\n"
     ]
    }
   ],
   "source": [
    "problem_id = random.choice(list(dataset.keys()))\n",
    "user_answer = random.choice(dataset[problem_id].user_answers)\n",
    "tokenized_answer = [word[0] for word in okt.pos(user_answer) if word[1] == 'Noun']\n",
    "print(tokenized_answer[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.backends.mps.is_available())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "be921176",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:03,  1.97it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [23]\u001B[0m, in \u001B[0;36m<cell line: 8>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     11\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m j, (user_answer, ground_truth) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(tqdm(\u001B[38;5;28mzip\u001B[39m(problem\u001B[38;5;241m.\u001B[39muser_answers, problem\u001B[38;5;241m.\u001B[39mground_truths))):\n\u001B[1;32m     12\u001B[0m     tokenized_answer \u001B[38;5;241m=\u001B[39m [word[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;28;01mfor\u001B[39;00m word \u001B[38;5;129;01min\u001B[39;00m okt\u001B[38;5;241m.\u001B[39mpos(user_answer) \u001B[38;5;28;01mif\u001B[39;00m word[\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mNoun\u001B[39m\u001B[38;5;124m'\u001B[39m]  \u001B[38;5;66;03m# 명사만 추출\u001B[39;00m\n\u001B[0;32m---> 13\u001B[0m     tokenized_answer_embedding \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencode\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtokenized_answer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     14\u001B[0m     similarity_scores \u001B[38;5;241m=\u001B[39m cosine_similarity(problem\u001B[38;5;241m.\u001B[39mkeywords_embedding, tokenized_answer_embedding)\n\u001B[1;32m     15\u001B[0m     predicts \u001B[38;5;241m=\u001B[39m [\u001B[38;5;241m1\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m score\u001B[38;5;241m.\u001B[39mmax() \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0.7\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;241m0\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m idx, score \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(similarity_scores)]\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/ai-resesarch/lib/python3.8/site-packages/sentence_transformers/SentenceTransformer.py:165\u001B[0m, in \u001B[0;36mSentenceTransformer.encode\u001B[0;34m(self, sentences, batch_size, show_progress_bar, output_value, convert_to_numpy, convert_to_tensor, device, normalize_embeddings)\u001B[0m\n\u001B[1;32m    162\u001B[0m features \u001B[38;5;241m=\u001B[39m batch_to_device(features, device)\n\u001B[1;32m    164\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[0;32m--> 165\u001B[0m     out_features \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfeatures\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    167\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m output_value \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtoken_embeddings\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m    168\u001B[0m         embeddings \u001B[38;5;241m=\u001B[39m []\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/ai-resesarch/lib/python3.8/site-packages/torch/nn/modules/container.py:139\u001B[0m, in \u001B[0;36mSequential.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    137\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[1;32m    138\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[0;32m--> 139\u001B[0m         \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[43mmodule\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    140\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/ai-resesarch/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1126\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1127\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1128\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1129\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1130\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1131\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1132\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/ai-resesarch/lib/python3.8/site-packages/sentence_transformers/models/Transformer.py:66\u001B[0m, in \u001B[0;36mTransformer.forward\u001B[0;34m(self, features)\u001B[0m\n\u001B[1;32m     63\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtoken_type_ids\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01min\u001B[39;00m features:\n\u001B[1;32m     64\u001B[0m     trans_features[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtoken_type_ids\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m features[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtoken_type_ids\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[0;32m---> 66\u001B[0m output_states \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mauto_model\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mtrans_features\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m     67\u001B[0m output_tokens \u001B[38;5;241m=\u001B[39m output_states[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m     69\u001B[0m features\u001B[38;5;241m.\u001B[39mupdate({\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtoken_embeddings\u001B[39m\u001B[38;5;124m'\u001B[39m: output_tokens, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mattention_mask\u001B[39m\u001B[38;5;124m'\u001B[39m: features[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mattention_mask\u001B[39m\u001B[38;5;124m'\u001B[39m]})\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/ai-resesarch/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1126\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1127\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1128\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1129\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1130\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1131\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1132\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/ai-resesarch/lib/python3.8/site-packages/transformers/models/roberta/modeling_roberta.py:847\u001B[0m, in \u001B[0;36mRobertaModel.forward\u001B[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[1;32m    838\u001B[0m head_mask \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_head_mask(head_mask, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mnum_hidden_layers)\n\u001B[1;32m    840\u001B[0m embedding_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39membeddings(\n\u001B[1;32m    841\u001B[0m     input_ids\u001B[38;5;241m=\u001B[39minput_ids,\n\u001B[1;32m    842\u001B[0m     position_ids\u001B[38;5;241m=\u001B[39mposition_ids,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    845\u001B[0m     past_key_values_length\u001B[38;5;241m=\u001B[39mpast_key_values_length,\n\u001B[1;32m    846\u001B[0m )\n\u001B[0;32m--> 847\u001B[0m encoder_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencoder\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    848\u001B[0m \u001B[43m    \u001B[49m\u001B[43membedding_output\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    849\u001B[0m \u001B[43m    \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mextended_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    850\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhead_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    851\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    852\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoder_attention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoder_extended_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    853\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpast_key_values\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpast_key_values\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    854\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_cache\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_cache\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    855\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    856\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    857\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    858\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    859\u001B[0m sequence_output \u001B[38;5;241m=\u001B[39m encoder_outputs[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m    860\u001B[0m pooled_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpooler(sequence_output) \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpooler \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/ai-resesarch/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1126\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1127\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1128\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1129\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1130\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1131\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1132\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/ai-resesarch/lib/python3.8/site-packages/transformers/models/roberta/modeling_roberta.py:523\u001B[0m, in \u001B[0;36mRobertaEncoder.forward\u001B[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[1;32m    514\u001B[0m     layer_outputs \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mutils\u001B[38;5;241m.\u001B[39mcheckpoint\u001B[38;5;241m.\u001B[39mcheckpoint(\n\u001B[1;32m    515\u001B[0m         create_custom_forward(layer_module),\n\u001B[1;32m    516\u001B[0m         hidden_states,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    520\u001B[0m         encoder_attention_mask,\n\u001B[1;32m    521\u001B[0m     )\n\u001B[1;32m    522\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 523\u001B[0m     layer_outputs \u001B[38;5;241m=\u001B[39m \u001B[43mlayer_module\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    524\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    525\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    526\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlayer_head_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    527\u001B[0m \u001B[43m        \u001B[49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    528\u001B[0m \u001B[43m        \u001B[49m\u001B[43mencoder_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    529\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpast_key_value\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    530\u001B[0m \u001B[43m        \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    531\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    533\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m layer_outputs[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m    534\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m use_cache:\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/ai-resesarch/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1126\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1127\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1128\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1129\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1130\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1131\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1132\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/ai-resesarch/lib/python3.8/site-packages/transformers/models/roberta/modeling_roberta.py:409\u001B[0m, in \u001B[0;36mRobertaLayer.forward\u001B[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001B[0m\n\u001B[1;32m    397\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\n\u001B[1;32m    398\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    399\u001B[0m     hidden_states: torch\u001B[38;5;241m.\u001B[39mTensor,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    406\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[torch\u001B[38;5;241m.\u001B[39mTensor]:\n\u001B[1;32m    407\u001B[0m     \u001B[38;5;66;03m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001B[39;00m\n\u001B[1;32m    408\u001B[0m     self_attn_past_key_value \u001B[38;5;241m=\u001B[39m past_key_value[:\u001B[38;5;241m2\u001B[39m] \u001B[38;5;28;01mif\u001B[39;00m past_key_value \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m--> 409\u001B[0m     self_attention_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mattention\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    410\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    411\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    412\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    413\u001B[0m \u001B[43m        \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    414\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpast_key_value\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mself_attn_past_key_value\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    415\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    416\u001B[0m     attention_output \u001B[38;5;241m=\u001B[39m self_attention_outputs[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m    418\u001B[0m     \u001B[38;5;66;03m# if decoder, the last output is tuple of self-attn cache\u001B[39;00m\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/ai-resesarch/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1126\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1127\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1128\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1129\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1130\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1131\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1132\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/ai-resesarch/lib/python3.8/site-packages/transformers/models/roberta/modeling_roberta.py:345\u001B[0m, in \u001B[0;36mRobertaAttention.forward\u001B[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001B[0m\n\u001B[1;32m    326\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\n\u001B[1;32m    327\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    328\u001B[0m     hidden_states: torch\u001B[38;5;241m.\u001B[39mTensor,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    334\u001B[0m     output_attentions: Optional[\u001B[38;5;28mbool\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m    335\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[torch\u001B[38;5;241m.\u001B[39mTensor]:\n\u001B[1;32m    336\u001B[0m     self_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mself(\n\u001B[1;32m    337\u001B[0m         hidden_states,\n\u001B[1;32m    338\u001B[0m         attention_mask,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    343\u001B[0m         output_attentions,\n\u001B[1;32m    344\u001B[0m     )\n\u001B[0;32m--> 345\u001B[0m     attention_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moutput\u001B[49m\u001B[43m(\u001B[49m\u001B[43mself_outputs\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    346\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m (attention_output,) \u001B[38;5;241m+\u001B[39m self_outputs[\u001B[38;5;241m1\u001B[39m:]  \u001B[38;5;66;03m# add attentions if we output them\u001B[39;00m\n\u001B[1;32m    347\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m outputs\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/ai-resesarch/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1126\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1127\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1128\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1129\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1130\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1131\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1132\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/ai-resesarch/lib/python3.8/site-packages/transformers/models/roberta/modeling_roberta.py:294\u001B[0m, in \u001B[0;36mRobertaSelfOutput.forward\u001B[0;34m(self, hidden_states, input_tensor)\u001B[0m\n\u001B[1;32m    293\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, hidden_states: torch\u001B[38;5;241m.\u001B[39mTensor, input_tensor: torch\u001B[38;5;241m.\u001B[39mTensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m torch\u001B[38;5;241m.\u001B[39mTensor:\n\u001B[0;32m--> 294\u001B[0m     hidden_states \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdense\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    295\u001B[0m     hidden_states \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdropout(hidden_states)\n\u001B[1;32m    296\u001B[0m     hidden_states \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mLayerNorm(hidden_states \u001B[38;5;241m+\u001B[39m input_tensor)\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/ai-resesarch/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1126\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1127\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1128\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1129\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1130\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1131\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1132\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/ai-resesarch/lib/python3.8/site-packages/torch/nn/modules/linear.py:114\u001B[0m, in \u001B[0;36mLinear.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    113\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m--> 114\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlinear\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# 유사도 검사\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tqdm import tqdm\n",
    "\n",
    "threshold = 0.7\n",
    "total_acc, total_f1 = 0, 0\n",
    "for i, key in enumerate(dataset):\n",
    "    acc, f1 = 0, 0\n",
    "    problem = dataset[key]\n",
    "    for j, (user_answer, ground_truth) in enumerate(tqdm(zip(problem.user_answers, problem.ground_truths))):\n",
    "        tokenized_answer = [word[0] for word in okt.pos(user_answer) if word[1] == 'Noun']  # 명사만 추출\n",
    "        tokenized_answer_embedding = model.encode(tokenized_answer)\n",
    "        similarity_scores = cosine_similarity(problem.keywords_embedding, tokenized_answer_embedding)\n",
    "        predicts = [1 if score.max() > 0.7 else 0 for idx, score in enumerate(similarity_scores)]\n",
    "        acc += accuracy_score(ground_truth, predicts)\n",
    "        f1 += f1_score(ground_truth, predicts, zero_division=0)\n",
    "    print(f\"{i}번 문제 점수 : accuracy : {acc / len(problem.user_answers)}, f1-score : {f1 / len(problem.user_answers)}\")\n",
    "    total_acc += acc / len(problem.user_answers)\n",
    "    total_f1 += f1 / len(problem.user_answers)\n",
    "print(f\"전체 문제 평균 accuracy : {total_acc / len(dataset)}, f1-score : {total_f1 / len(dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700efb62",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "problem_id = random.choice(list(dataset.keys()))\n",
    "user_answer = random.choice(dataset[problem_id].user_answers)\n",
    "tokenized_answer = [word[0] for word in okt.pos(user_answer) if word[1] in ('Noun', 'Alpha')]\n",
    "print(tokenized_answer[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93834dc",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 유사도 검사 -> 영어도 추가\n",
    "threshold = 0.7\n",
    "total_acc, total_f1 = 0, 0\n",
    "for i, key in enumerate(dataset):\n",
    "    acc, f1 = 0, 0\n",
    "    problem = dataset[key]\n",
    "    for j, (user_answer, ground_truth) in enumerate(tqdm(zip(problem.user_answers, problem.ground_truths))):\n",
    "        tokenized_answer = [word[0] for word in okt.pos(user_answer) if word[1] in ('Noun', 'Alpha')]  # 명사만 추출\n",
    "        tokenized_answer_embedding = model.encode(tokenized_answer)\n",
    "        similarity_scores = cosine_similarity(problem.keywords_embedding, tokenized_answer_embedding)\n",
    "        predicts = [1 if score.max() > 0.7 else 0 for idx, score in enumerate(similarity_scores)]\n",
    "        acc += accuracy_score(ground_truth, predicts)\n",
    "        f1 += f1_score(ground_truth, predicts, zero_division=0)\n",
    "    print(f\"{i}번 문제 점수 : accuracy : {acc / len(problem.user_answers)}, f1-score : {f1 / len(problem.user_answers)}\")\n",
    "    total_acc += acc / len(problem.user_answers)\n",
    "    total_f1 += f1 / len(problem.user_answers)\n",
    "print(f\"전체 문제 평균 accuracy : {total_acc / len(dataset)}, f1-score : {total_f1 / len(dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541405e9",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "---\n",
    "### 2번이랑 3번이랑 아니 그냥 전체적으로 엉망진창이네!!\n",
    "### 성능 향상을 위한 방법들은 아래와 같다.\n",
    "- Tokenizing을 하지 않고 n-gram 방식으로 대조\n",
    "- 키워드를 조금 더 적합한 단어로 변경\n",
    "- 여러개의 키워드 후보군을 비교\n",
    "- 불용어 제거\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b62106b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for i, problem_id in enumerate(dataset):\n",
    "    problem = dataset[problem_id]\n",
    "    print(f\"{i}번째 문제 ID : {problem_id}\")\n",
    "    print(f\"{i}번째 문제 : {problem.subject}\")\n",
    "    print(f\"keyword : {problem.keywords}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4166b372",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(dataset['recXfKthnQLwWETgb'].keywords)\n",
    "dataset['recXfKthnQLwWETgb'].keywords[0] = \"만료\"  # Lifecycle -> 만료\n",
    "print(dataset['recXfKthnQLwWETgb'].keywords)\n",
    "dataset['recXfKthnQLwWETgb'].keywords_embedding = model.encode(dataset['recXfKthnQLwWETgb'].keywords)  # 1번\n",
    "print(dataset['rec1QvAvB4CMami3p'].keywords)\n",
    "dataset['rec1QvAvB4CMami3p'].keywords[2] = '스택'  # Stack -> 스택\n",
    "print(dataset['rec1QvAvB4CMami3p'].keywords)\n",
    "dataset['rec1QvAvB4CMami3p'].keywords_embedding = model.encode(dataset['rec1QvAvB4CMami3p'].keywords)  # 7번\n",
    "print(dataset['recUcGjT9Xkb7N5pu'].keywords)\n",
    "dataset['recUcGjT9Xkb7N5pu'].keywords[2] = \"삭제\"  # 삭제(POP) -> 삭제\n",
    "dataset['recUcGjT9Xkb7N5pu'].keywords[3] = \"삽입\"  # 삽입(PUSH) -> 삽입\n",
    "print(dataset['recUcGjT9Xkb7N5pu'].keywords)\n",
    "dataset['recUcGjT9Xkb7N5pu'].keywords_embedding = model.encode(dataset['recUcGjT9Xkb7N5pu'].keywords)  # 10번"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b24d29",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "problem_id = random.choice(list(dataset.keys()))\n",
    "split_answer = random.choice(dataset[problem_id].user_answers).split(' ')\n",
    "word_concat_size = 2\n",
    "tokenized_answer = []\n",
    "for k in range(len(split_answer) - word_concat_size):\n",
    "    tokenized_answer.append(' '.join(split_answer[k : k + word_concat_size]))\n",
    "print(tokenized_answer[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fee420",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 유사도 검사 -> Tokenizer 방식에서 띄어쓰기 단위로 2개씩 묶어서 window 방식으로 비교 + 키워드 변형\n",
    "threshold = 0.7\n",
    "total_acc, total_f1 = 0, 0\n",
    "word_concat_size = 2\n",
    "\n",
    "for i, key in enumerate(dataset):\n",
    "    acc, f1 = 0, 0\n",
    "    problem = dataset[key]\n",
    "    for j, (user_answer, ground_truth) in enumerate(tqdm(zip(problem.user_answers, problem.ground_truths))):\n",
    "        split_answer = user_answer.split(' ')\n",
    "        tokenized_answer = []\n",
    "        for k in range(len(split_answer) - word_concat_size):\n",
    "            tokenized_answer.append(' '.join(split_answer[k : k + word_concat_size]))\n",
    "        tokenized_answer_embedding = model.encode(tokenized_answer)\n",
    "        similarity_scores = cosine_similarity(problem.keywords_embedding, tokenized_answer_embedding)\n",
    "        predicts = [1 if score.max() > threshold else 0 for idx, score in enumerate(similarity_scores)]\n",
    "        acc += accuracy_score(ground_truth, predicts)\n",
    "        f1 += f1_score(ground_truth, predicts, zero_division=0)\n",
    "    print(f\"{i}번 문제 점수 : accuracy : {acc / len(problem.user_answers)}, f1-score : {f1 / len(problem.user_answers)}\")\n",
    "    total_acc += acc / len(problem.user_answers)\n",
    "    total_f1 += f1 / len(problem.user_answers)\n",
    "print(f\"전체 문제 평균 accuracy : {total_acc / len(dataset)}, f1-score : {total_f1 / len(dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abea29e5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 유사도 검사 -> Tokenizer 방식에서 띄어쓰기 단위로 2개씩 묶어서 window 방식으로 비교 + 키워드 변형, threshold 0.5로 낮춤\n",
    "threshold = 0.5\n",
    "total_acc, total_f1 = 0, 0\n",
    "word_concat_size = 2\n",
    "\n",
    "for i, key in enumerate(dataset):\n",
    "    acc, f1 = 0, 0\n",
    "    problem = dataset[key]\n",
    "    for j, (user_answer, ground_truth) in enumerate(tqdm(zip(problem.user_answers, problem.ground_truths))):\n",
    "        split_answer = user_answer.split(' ')\n",
    "        tokenized_answer = []\n",
    "        for k in range(len(split_answer) - word_concat_size):\n",
    "            tokenized_answer.append(' '.join(split_answer[k : k + word_concat_size]))\n",
    "        tokenized_answer_embedding = model.encode(tokenized_answer)\n",
    "        similarity_scores = cosine_similarity(problem.keywords_embedding, tokenized_answer_embedding)\n",
    "        predicts = [1 if score.max() > threshold else 0 for idx, score in enumerate(similarity_scores)]\n",
    "        acc += accuracy_score(ground_truth, predicts)\n",
    "        f1 += f1_score(ground_truth, predicts, zero_division=0)\n",
    "    print(f\"{i}번 문제 점수 : accuracy : {acc / len(problem.user_answers)}, f1-score : {f1 / len(problem.user_answers)}\")\n",
    "    total_acc += acc / len(problem.user_answers)\n",
    "    total_f1 += f1 / len(problem.user_answers)\n",
    "print(f\"전체 문제 평균 accuracy : {total_acc / len(dataset)}, f1-score : {total_f1 / len(dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c69934",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "problem_id = random.choice(list(dataset.keys()))\n",
    "split_answer = random.choice(dataset[problem_id].user_answers).split(' ')\n",
    "word_concat_size = 3\n",
    "tokenized_answer = []\n",
    "for k in range(len(split_answer) - word_concat_size):\n",
    "    tokenized_answer.append(' '.join(split_answer[k : k + word_concat_size]))\n",
    "print(tokenized_answer[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d612042a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 유사도 검사 -> Tokenizer 방식에서 띄어쓰기 단위로 2개씩 묶어서 window 방식으로 비교 + 키워드 변형 -> 윈도우 사이즈 3으로 늘림, threshold 0.35로 낮춤\n",
    "threshold = 0.35\n",
    "total_acc, total_f1 = 0, 0\n",
    "word_concat_size = 3\n",
    "\n",
    "for i, key in enumerate(dataset):\n",
    "    acc, f1 = 0, 0\n",
    "    problem = dataset[key]\n",
    "    for j, (user_answer, ground_truth) in enumerate(tqdm(zip(problem.user_answers, problem.ground_truths))):\n",
    "        split_answer = user_answer.split(' ')\n",
    "        tokenized_answer = []\n",
    "        for k in range(len(split_answer) - word_concat_size + 1):\n",
    "            tokenized_answer.append(' '.join(split_answer[k : k + word_concat_size]))\n",
    "        if len(split_answer) < word_concat_size:\n",
    "            tokenized_answer.append(' '.join(split_answer))\n",
    "        tokenized_answer_embedding = model.encode(tokenized_answer)\n",
    "        similarity_scores = cosine_similarity(problem.keywords_embedding, tokenized_answer_embedding)\n",
    "        predicts = [1 if score.max() > threshold else 0 for idx, score in enumerate(similarity_scores)]\n",
    "\n",
    "        acc += accuracy_score(ground_truth, predicts)\n",
    "        f1 += f1_score(ground_truth, predicts, zero_division=1)\n",
    "    print(f\"{i}번 문제 점수 : accuracy : {acc / len(problem.user_answers)}, f1-score : {f1 / len(problem.user_answers)}\")\n",
    "    total_acc += acc / len(problem.user_answers)\n",
    "    total_f1 += f1 / len(problem.user_answers)\n",
    "print(f\"전체 문제 평균 accuracy : {total_acc / len(dataset)}, f1-score : {total_f1 / len(dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72409213",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "---\n",
    "### 왜 5번문제만 f1 score가 저 모양일까?\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebddccb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "problem = dataset['recio3s0A77i0kkEn']\n",
    "\n",
    "print(problem.subject)\n",
    "print(f\"정답 키워드 : {problem.keywords}\")\n",
    "keyword_count = {}\n",
    "for answer, keywords in zip(problem.user_answers, problem.user_correct_keywords):\n",
    "    for keyword in keywords:\n",
    "        if keyword not in keyword_count:\n",
    "            keyword_count[keyword] = 1\n",
    "        else:\n",
    "            keyword_count[keyword] += 1\n",
    "for keyword in keyword_count:\n",
    "    keyword_count[keyword] = f\"{int(keyword_count[keyword] / len(problem.user_answers) * 100)}%\"\n",
    "print(keyword_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0884aa8b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "---\n",
    "#### 자세히 보면 키워드가 너무 어려웠는지 정답률이 엉망이다.\n",
    "#### 실제 정답에 1이 없다면 f1 score는 무조건 0이다.\n",
    "#### 이는 키워드가 적절치 않았는지를 고려해봐야 할 듯 하다.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e08ca3",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "---\n",
    "### 이제 실제로 모델이 어떻게 예측하고 있는지 눈으로 확인해보자!!\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03fcf98",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 유사도 검사 -> Tokenizer 방식에서 띄어쓰기 단위로 2개씩 묶어서 window 방식으로 비교 + 키워드 변형 -> 윈도우 사이즈 3으로 늘림\n",
    "threshold = 0.35\n",
    "total_acc, total_f1 = 0, 0\n",
    "word_concat_size = 3\n",
    "\n",
    "for i, key in enumerate(dataset):\n",
    "    acc, f1 = 0, 0\n",
    "    problem = dataset[key]\n",
    "    for j, (user_answer, ground_truth) in enumerate(tqdm(zip(problem.user_answers, problem.ground_truths))):\n",
    "        if j == 10:\n",
    "            break\n",
    "        split_answer = user_answer.split(' ')\n",
    "        tokenized_answer = []\n",
    "        for k in range(len(split_answer) - word_concat_size + 1):\n",
    "            tokenized_answer.append(' '.join(split_answer[k : k + word_concat_size]))\n",
    "        if len(split_answer) < word_concat_size:\n",
    "            tokenized_answer.append(' '.join(split_answer))\n",
    "        tokenized_answer_embedding = model.encode(tokenized_answer)\n",
    "        similarity_scores = cosine_similarity(problem.keywords_embedding, tokenized_answer_embedding)\n",
    "        predicts = []\n",
    "        for z, idx in enumerate(similarity_scores.argmax(axis=1)):\n",
    "            if threshold < similarity_scores[z][idx]:\n",
    "                print(f\"keyword          : {problem.keywords[z]}\")\n",
    "                print(f\"detected keyword : {tokenized_answer[idx]}\")\n",
    "                predicts.append(1)\n",
    "            else:\n",
    "                predicts.append(0)\n",
    "        print(f\"실제 정답 : {problem.user_correct_keywords[j]}\")\n",
    "        acc += accuracy_score(ground_truth, predicts)\n",
    "        f1 += f1_score(ground_truth, predicts, zero_division=1)\n",
    "    print(f\"{i}번 문제 점수 : accuracy : {acc / len(problem.user_answers)}, f1-score : {f1 / len(problem.user_answers)}\")\n",
    "    total_acc += acc / len(problem.user_answers)\n",
    "    total_f1 += f1 / len(problem.user_answers)\n",
    "print(f\"전체 문제 평균 accuracy : {total_acc / len(dataset)}, f1-score : {total_f1 / len(dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515cd524",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "---\n",
    "### 처음에 tokenized 되면서 영어들이 무시되었기 때문에 영어로 구성된 키워드들을 한글로 변형 시켰지만 스윽 보니 이제 영어도 잘 찾네요!!\n",
    "### 그럼 다시 이전 키워드들로 변경해서 성능을 비교해봅시다\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227a0bd6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(dataset['recXfKthnQLwWETgb'].keywords)\n",
    "dataset['recXfKthnQLwWETgb'].keywords[0] = \"Lifecycle\"  # 만료 -> Lifecycle\n",
    "print(dataset['recXfKthnQLwWETgb'].keywords)\n",
    "dataset['recXfKthnQLwWETgb'].keywords_embedding = model.encode(dataset['recXfKthnQLwWETgb'].keywords)  # 1번\n",
    "print(dataset['recUcGjT9Xkb7N5pu'].keywords)\n",
    "dataset['recUcGjT9Xkb7N5pu'].keywords[2] = \"삭제(POP)\"  # 삭제 -> 삭제(POP)\n",
    "dataset['recUcGjT9Xkb7N5pu'].keywords[3] = \"삽입(PUSH)\"  # 삽입 -> 삽입(PUSH)\n",
    "print(dataset['recUcGjT9Xkb7N5pu'].keywords)\n",
    "dataset['recUcGjT9Xkb7N5pu'].keywords_embedding = model.encode(dataset['recUcGjT9Xkb7N5pu'].keywords)  # 10번\n",
    "print(dataset['rec1QvAvB4CMami3p'].keywords)\n",
    "dataset['rec1QvAvB4CMami3p'].keywords[2] = 'Stack'  # 스택 -> Stack\n",
    "dataset['rec1QvAvB4CMami3p'].keywords_embedding = model.encode(dataset['rec1QvAvB4CMami3p'].keywords)  # 7번\n",
    "print(dataset['rec1QvAvB4CMami3p'].keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3e6b36",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 유사도 검사 -> Tokenizer 방식에서 띄어쓰기 단위로 3개씩 묶어서 window 방식으로 비교 + 키워드 변형 -> 윈도우 사이즈 3으로 늘림\n",
    "threshold = 0.35\n",
    "total_acc, total_f1 = 0, 0\n",
    "word_concat_size = 3\n",
    "\n",
    "for i, key in enumerate(dataset):\n",
    "    acc, f1 = 0, 0\n",
    "    problem = dataset[key]\n",
    "    for j, (user_answer, ground_truth) in enumerate(tqdm(zip(problem.user_answers, problem.ground_truths))):\n",
    "        split_answer = user_answer.split(' ')\n",
    "        tokenized_answer = []\n",
    "        for k in range(len(split_answer) - word_concat_size + 1):\n",
    "            tokenized_answer.append(' '.join(split_answer[k : k + word_concat_size]))\n",
    "        if len(split_answer) < word_concat_size:\n",
    "            tokenized_answer.append(' '.join(split_answer))\n",
    "        tokenized_answer_embedding = model.encode(tokenized_answer)\n",
    "        similarity_scores = cosine_similarity(problem.keywords_embedding, tokenized_answer_embedding)\n",
    "        predicts = [1 if score.max() > threshold else 0 for idx, score in enumerate(similarity_scores)]\n",
    "\n",
    "        acc += accuracy_score(ground_truth, predicts)\n",
    "        f1 += f1_score(ground_truth, predicts, zero_division=1)\n",
    "    print(f\"{i}번 문제 점수 : accuracy : {acc / len(problem.user_answers)}, f1-score : {f1 / len(problem.user_answers)}\")\n",
    "    total_acc += acc / len(problem.user_answers)\n",
    "    total_f1 += f1 / len(problem.user_answers)\n",
    "print(f\"전체 문제 평균 accuracy : {total_acc / len(dataset)}, f1-score : {total_f1 / len(dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974f551a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "---\n",
    "### 1번 문제 : 만료 -> Lifecycle [성능 소폭 하락]\n",
    "### 7번 문제 : 삽입 -> 스택 -> Stack [성능 상승]\n",
    "### 10번 문제 : 삭제 -> 삭제(POP), 삽입 -> 삽입(PUSH) [성능 하락]\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d493e927",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "---\n",
    "### 이번에는 여러개의 키워드라면 쉼표로 구분해서 넣어줘보자\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8948e98f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(dataset['recXfKthnQLwWETgb'].keywords)\n",
    "dataset['recXfKthnQLwWETgb'].keywords[0] = \"만료, Lifecycle\"\n",
    "print(dataset['recXfKthnQLwWETgb'].keywords)\n",
    "dataset['recXfKthnQLwWETgb'].keywords_embedding = model.encode(dataset['recXfKthnQLwWETgb'].keywords)  # 1번\n",
    "print(dataset['recUcGjT9Xkb7N5pu'].keywords)\n",
    "dataset['recUcGjT9Xkb7N5pu'].keywords[2] = \"삭제, POP\"  # 삭제 -> 삭제(POP)\n",
    "dataset['recUcGjT9Xkb7N5pu'].keywords[3] = \"삽입, PUSH\"  # 삽입 -> 삽입(PUSH)\n",
    "print(dataset['recUcGjT9Xkb7N5pu'].keywords)\n",
    "dataset['recUcGjT9Xkb7N5pu'].keywords_embedding = model.encode(dataset['recUcGjT9Xkb7N5pu'].keywords)  # 10번\n",
    "print(dataset['rec1QvAvB4CMami3p'].keywords)\n",
    "dataset['rec1QvAvB4CMami3p'].keywords[2] = 'Stack'  # 스택 -> Stack\n",
    "dataset['rec1QvAvB4CMami3p'].keywords_embedding = model.encode(dataset['rec1QvAvB4CMami3p'].keywords)  # 7번\n",
    "print(dataset['rec1QvAvB4CMami3p'].keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b81dc08",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 유사도 검사 -> Tokenizer 방식에서 띄어쓰기 단위로 2개씩 묶어서 window 방식으로 비교 + 키워드 변형 -> 윈도우 사이즈 3으로 늘림\n",
    "threshold = 0.35\n",
    "total_acc, total_f1 = 0, 0\n",
    "word_concat_size = 3\n",
    "\n",
    "for i, key in enumerate(dataset):\n",
    "    acc, f1 = 0, 0\n",
    "    problem = dataset[key]\n",
    "    for j, (user_answer, ground_truth) in enumerate(tqdm(zip(problem.user_answers, problem.ground_truths))):\n",
    "        split_answer = user_answer.split(' ')\n",
    "        tokenized_answer = []\n",
    "        for k in range(len(split_answer) - word_concat_size + 1):\n",
    "            tokenized_answer.append(' '.join(split_answer[k : k + word_concat_size]))\n",
    "        if len(split_answer) < word_concat_size:\n",
    "            tokenized_answer.append(' '.join(split_answer))\n",
    "        tokenized_answer_embedding = model.encode(tokenized_answer)\n",
    "        similarity_scores = cosine_similarity(problem.keywords_embedding, tokenized_answer_embedding)\n",
    "        predicts = [1 if score.max() > threshold else 0 for idx, score in enumerate(similarity_scores)]\n",
    "\n",
    "        acc += accuracy_score(ground_truth, predicts)\n",
    "        f1 += f1_score(ground_truth, predicts, zero_division=1)\n",
    "    print(f\"{i}번 문제 점수 : accuracy : {acc / len(problem.user_answers)}, f1-score : {f1 / len(problem.user_answers)}\")\n",
    "    total_acc += acc / len(problem.user_answers)\n",
    "    total_f1 += f1 / len(problem.user_answers)\n",
    "print(f\"전체 문제 평균 accuracy : {total_acc / len(dataset)}, f1-score : {total_f1 / len(dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2f2e36",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "---\n",
    "### 꽤 유의미한 결과다!!\n",
    "### 마지막으로 word concat size를 2로 줄여서 두개의 단어씩만 비교해보자\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b529166f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "problem_id = random.choice(list(dataset.keys()))\n",
    "\n",
    "split_answer = random.choice(dataset[problem_id].user_answers).split(' ')\n",
    "word_concat_size = 2\n",
    "tokenized_answer = []\n",
    "for k in range(len(split_answer) - word_concat_size):\n",
    "    tokenized_answer.append(' '.join(split_answer[k : k + word_concat_size]))\n",
    "print(tokenized_answer[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a997d7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 유사도 검사 -> Tokenizer 방식에서 띄어쓰기 단위로 2개씩 묶어서 window 방식으로 비교 + 키워드 변형 -> 윈도우 사이즈 3으로 늘림\n",
    "threshold = 0.35\n",
    "total_acc, total_f1 = 0, 0\n",
    "word_concat_size = 2\n",
    "\n",
    "for i, key in enumerate(dataset):\n",
    "    acc, f1 = 0, 0\n",
    "    problem = dataset[key]\n",
    "    for j, (user_answer, ground_truth) in enumerate(tqdm(zip(problem.user_answers, problem.ground_truths))):\n",
    "        split_answer = user_answer.split(' ')\n",
    "        tokenized_answer = []\n",
    "        for k in range(len(split_answer) - word_concat_size + 1):\n",
    "            tokenized_answer.append(' '.join(split_answer[k : k + word_concat_size]))\n",
    "        if len(split_answer) < word_concat_size:\n",
    "            tokenized_answer.append(' '.join(split_answer))\n",
    "        tokenized_answer_embedding = model.encode(tokenized_answer)\n",
    "        similarity_scores = cosine_similarity(problem.keywords_embedding, tokenized_answer_embedding)\n",
    "        predicts = [1 if score.max() > threshold else 0 for idx, score in enumerate(similarity_scores)]\n",
    "\n",
    "        acc += accuracy_score(ground_truth, predicts)\n",
    "        f1 += f1_score(ground_truth, predicts, zero_division=1)\n",
    "    print(f\"{i}번 문제 점수 : accuracy : {acc / len(problem.user_answers)}, f1-score : {f1 / len(problem.user_answers)}\")\n",
    "    total_acc += acc / len(problem.user_answers)\n",
    "    total_f1 += f1 / len(problem.user_answers)\n",
    "print(f\"전체 문제 평균 accuracy : {total_acc / len(dataset)}, f1-score : {total_f1 / len(dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22274f39",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "---\n",
    "### 전체 정확도는 조금 떨어졌지만 분명 2개씩 봤을 때 성능이 더 좋은 문제들이 있다.\n",
    "### 확실하게 하려면 다음부터는 2개씩 보는 것과 3개씩 보는 것, 그리고 쉼표로 여러 키워드 후보를 비교해보는게 아닌 각각 여러개 비교하기까지 하면 성능이 꽤나 좋아질 것 같다.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5953d1",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 마지막으로 윈도우 사이즈를 2개와 3개를 합쳐서 해보자!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a57531",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "problem_id = random.choice(list(dataset.keys()))\n",
    "split_answer = random.choice(dataset[problem_id].user_answers).split(' ')\n",
    "word_concat_size = 2\n",
    "for k in range(len(split_answer) - word_concat_size + 1):\n",
    "    tokenized_answer.append(' '.join(split_answer[k : k + word_concat_size]))\n",
    "word_concat_size = 3\n",
    "for k in range(len(split_answer) - word_concat_size + 1):\n",
    "    tokenized_answer.append(' '.join(split_answer[k : k + word_concat_size]))\n",
    "print(tokenized_answer[:3])\n",
    "print(tokenized_answer[-3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3f7f13",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 유사도 검사 -> Tokenizer 방식에서 띄어쓰기 단위로 2개씩 묶어서 window 방식으로 비교 + 키워드 변형 -> 윈도우 사이즈 3으로 늘림\n",
    "threshold = 0.35\n",
    "total_acc, total_f1 = 0, 0\n",
    "\n",
    "for i, key in enumerate(dataset):\n",
    "    acc, f1 = 0, 0\n",
    "    problem = dataset[key]\n",
    "    for j, (user_answer, ground_truth) in enumerate(tqdm(zip(problem.user_answers, problem.ground_truths))):\n",
    "        split_answer = user_answer.split(' ')\n",
    "        tokenized_answer = []\n",
    "        word_concat_size = 2\n",
    "        for k in range(len(split_answer) - word_concat_size + 1):\n",
    "            tokenized_answer.append(' '.join(split_answer[k : k + word_concat_size]))\n",
    "        word_concat_size = 3\n",
    "        for k in range(len(split_answer) - word_concat_size + 1):\n",
    "            tokenized_answer.append(' '.join(split_answer[k : k + word_concat_size]))\n",
    "        if not tokenized_answer:\n",
    "            tokenized_answer.append(' '.join(split_answer))\n",
    "        tokenized_answer_embedding = model.encode(tokenized_answer)\n",
    "        similarity_scores = cosine_similarity(problem.keywords_embedding, tokenized_answer_embedding)\n",
    "        predicts = [1 if score.max() > threshold else 0 for idx, score in enumerate(similarity_scores)]\n",
    "\n",
    "        acc += accuracy_score(ground_truth, predicts)\n",
    "        f1 += f1_score(ground_truth, predicts, zero_division=1)\n",
    "    print(f\"{i}번 문제 점수 : accuracy : {acc / len(problem.user_answers)}, f1-score : {f1 / len(problem.user_answers)}\")\n",
    "    total_acc += acc / len(problem.user_answers)\n",
    "    total_f1 += f1 / len(problem.user_answers)\n",
    "print(f\"전체 문제 평균 accuracy : {total_acc / len(dataset)}, f1-score : {total_f1 / len(dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ceea38",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 하지만 이런 방식은 너무 느리다. GPU를 사용한다해도 이는 감당이 안될 수 있다.\n",
    "### 그리고 정확도도 그리 좋아지지 않았다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a243db3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
