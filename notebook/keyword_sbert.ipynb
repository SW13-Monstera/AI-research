{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "##%% md\n",
    "## !pip install sentence_transformers"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer(\"Huffon/sentence-klue-roberta-base\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('user_answer.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "outputs": [
    {
     "data": {
      "text/plain": "            problem_id                        problem   assign  \\\n0    recXfKthnQLwWETgb  [네트워크 1] 쿠키와 세션의 차이점을 설명해주세요.     jack   \n1    recXfKthnQLwWETgb  [네트워크 1] 쿠키와 세션의 차이점을 설명해주세요.     jack   \n2    recXfKthnQLwWETgb  [네트워크 1] 쿠키와 세션의 차이점을 설명해주세요.     jack   \n3    recXfKthnQLwWETgb  [네트워크 1] 쿠키와 세션의 차이점을 설명해주세요.     jack   \n4    recXfKthnQLwWETgb  [네트워크 1] 쿠키와 세션의 차이점을 설명해주세요.     jack   \n..                 ...                            ...      ...   \n445  recUcGjT9Xkb7N5pu    [자료구조 3] Queue의 특징을 설명해주세요.  kshired   \n446  recUcGjT9Xkb7N5pu    [자료구조 3] Queue의 특징을 설명해주세요.  kshired   \n447  recUcGjT9Xkb7N5pu    [자료구조 3] Queue의 특징을 설명해주세요.  kshired   \n448  recUcGjT9Xkb7N5pu    [자료구조 3] Queue의 특징을 설명해주세요.  kshired   \n449  recUcGjT9Xkb7N5pu    [자료구조 3] Queue의 특징을 설명해주세요.  kshired   \n\n                                           user_answer  \\\n0    쿠키는 개인 PC에 text로 저장된다. 세션은 접속중인 웹 서버에 Object로 ...   \n1    세션이 쿠키에 비해 보안도 높은 편이나 쿠키를 사용하는 이유는세션은 서버에 저장되고...   \n2    쿠키와 세션의 가장 큰 차이점은 정보가 저장되는 위치입니다. 쿠키는 서버의 자원을 ...   \n3    쿠키는 클라이언트 로컬에 저장되기 때문에 변질되거나 request에서 스니핑 당할 ...   \n4    쿠키도 만료시간이 있지만 파일로 저장되기 때문에 브라우저를 종료해도 계속해서 정보가...   \n..                                                 ...   \n445  데이터가 삽입된 순서대로 삭제되는 선입선출(FIFO, First-In-First-O...   \n446  선입선출(FIFO, First in first out) 방식의 자료구조를 말한다. ...   \n447  큐는 스택 자료구조와 달리 FIFO (First-In First-Out)- 선입 선...   \n448  큐(Queue)는 FIFO(First In First Out) 의 특징을 갖는 자료...   \n449  선입선출(FIFO, First in first out) 방식의 자료구조를 말한다. ...   \n\n                                     scoring_criterion  \\\n0    ['세션이 쿠키보다 보안에 유리하다는 내용 - 1점', '세션이 쿠키보다 속도가 느...   \n1    ['세션이 쿠키보다 보안에 유리하다는 내용 - 1점', '세션이 쿠키보다 속도가 느...   \n2    ['세션이 쿠키보다 보안에 유리하다는 내용 - 1점', '세션이 쿠키보다 속도가 느...   \n3    ['세션이 쿠키보다 보안에 유리하다는 내용 - 1점', '세션이 쿠키보다 속도가 느...   \n4    ['세션이 쿠키보다 보안에 유리하다는 내용 - 1점', '세션이 쿠키보다 속도가 느...   \n..                                                 ...   \n445  ['rear에서 자료의 삽입이 front에서 자료의 삭제가 이루어짐 - 1점', '...   \n446  ['rear에서 자료의 삽입이 front에서 자료의 삭제가 이루어짐 - 1점', '...   \n447  ['rear에서 자료의 삽입이 front에서 자료의 삭제가 이루어짐 - 1점', '...   \n448  ['rear에서 자료의 삽입이 front에서 자료의 삭제가 이루어짐 - 1점', '...   \n449  ['rear에서 자료의 삽입이 front에서 자료의 삭제가 이루어짐 - 1점', '...   \n\n                             correct_scoring_criterion  \\\n0    ['세션이 쿠키보다 속도가 느리다는 내용 - 1점', '저장위치가 쿠키는 클라이언트...   \n1    ['세션이 쿠키보다 보안에 유리하다는 내용 - 1점', '세션이 쿠키보다 속도가 느...   \n2    ['세션이 쿠키보다 보안에 유리하다는 내용 - 1점', '세션이 쿠키보다 속도가 느...   \n3    ['세션이 쿠키보다 보안에 유리하다는 내용 - 1점', '저장위치가 쿠키는 클라이언...   \n4                            ['Lifecycle에 대한 내용 - 1점']   \n..                                                 ...   \n445  ['rear에서 자료의 삽입이 front에서 자료의 삭제가 이루어짐 - 1점', '...   \n446  ['rear에서 자료의 삽입이 front에서 자료의 삭제가 이루어짐 - 1점', '...   \n447  ['rear에서 자료의 삽입이 front에서 자료의 삭제가 이루어짐 - 1점', '...   \n448  ['rear에서 자료의 삽입이 front에서 자료의 삭제가 이루어짐 - 1점', '...   \n449  ['rear에서 자료의 삽입이 front에서 자료의 삭제가 이루어짐 - 1점', '...   \n\n                                     keyword_criterion  \\\n0    ['Lifecycle - 1점', '보안 - 1점', '저장위치 - 2점', '속도...   \n1    ['Lifecycle - 1점', '보안 - 1점', '저장위치 - 2점', '속도...   \n2    ['Lifecycle - 1점', '보안 - 1점', '저장위치 - 2점', '속도...   \n3    ['Lifecycle - 1점', '보안 - 1점', '저장위치 - 2점', '속도...   \n4    ['Lifecycle - 1점', '보안 - 1점', '저장위치 - 2점', '속도...   \n..                                                 ...   \n445  ['시간복잡도 - 1점', 'FIFO - 2점', '삭제(POP) - 1점', '삽...   \n446  ['시간복잡도 - 1점', 'FIFO - 2점', '삭제(POP) - 1점', '삽...   \n447  ['시간복잡도 - 1점', 'FIFO - 2점', '삭제(POP) - 1점', '삽...   \n448  ['시간복잡도 - 1점', 'FIFO - 2점', '삭제(POP) - 1점', '삽...   \n449  ['시간복잡도 - 1점', 'FIFO - 2점', '삭제(POP) - 1점', '삽...   \n\n                             correct_keyword_criterion          annotator  \n0                             ['저장위치 - 2점', '속도 - 1점']  mjw8523@gmail.com  \n1                  ['보안 - 1점', '저장위치 - 2점', '속도 - 1점']  mjw8523@gmail.com  \n2                  ['보안 - 1점', '저장위치 - 2점', '속도 - 1점']  mjw8523@gmail.com  \n3                             ['보안 - 1점', '저장위치 - 2점']  mjw8523@gmail.com  \n4                                   ['Lifecycle - 1점']  mjw8523@gmail.com  \n..                                                 ...                ...  \n445  ['시간복잡도 - 1점', 'FIFO - 2점', '삭제(POP) - 1점', '삽...  mjw8523@gmail.com  \n446     ['FIFO - 2점', '삭제(POP) - 1점', '삽입(PUSH) - 1점']  mjw8523@gmail.com  \n447     ['FIFO - 2점', '삭제(POP) - 1점', '삽입(PUSH) - 1점']  mjw8523@gmail.com  \n448     ['FIFO - 2점', '삭제(POP) - 1점', '삽입(PUSH) - 1점']  mjw8523@gmail.com  \n449     ['FIFO - 2점', '삭제(POP) - 1점', '삽입(PUSH) - 1점']  mjw8523@gmail.com  \n\n[450 rows x 9 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>problem_id</th>\n      <th>problem</th>\n      <th>assign</th>\n      <th>user_answer</th>\n      <th>scoring_criterion</th>\n      <th>correct_scoring_criterion</th>\n      <th>keyword_criterion</th>\n      <th>correct_keyword_criterion</th>\n      <th>annotator</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>recXfKthnQLwWETgb</td>\n      <td>[네트워크 1] 쿠키와 세션의 차이점을 설명해주세요.</td>\n      <td>jack</td>\n      <td>쿠키는 개인 PC에 text로 저장된다. 세션은 접속중인 웹 서버에 Object로 ...</td>\n      <td>['세션이 쿠키보다 보안에 유리하다는 내용 - 1점', '세션이 쿠키보다 속도가 느...</td>\n      <td>['세션이 쿠키보다 속도가 느리다는 내용 - 1점', '저장위치가 쿠키는 클라이언트...</td>\n      <td>['Lifecycle - 1점', '보안 - 1점', '저장위치 - 2점', '속도...</td>\n      <td>['저장위치 - 2점', '속도 - 1점']</td>\n      <td>mjw8523@gmail.com</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>recXfKthnQLwWETgb</td>\n      <td>[네트워크 1] 쿠키와 세션의 차이점을 설명해주세요.</td>\n      <td>jack</td>\n      <td>세션이 쿠키에 비해 보안도 높은 편이나 쿠키를 사용하는 이유는세션은 서버에 저장되고...</td>\n      <td>['세션이 쿠키보다 보안에 유리하다는 내용 - 1점', '세션이 쿠키보다 속도가 느...</td>\n      <td>['세션이 쿠키보다 보안에 유리하다는 내용 - 1점', '세션이 쿠키보다 속도가 느...</td>\n      <td>['Lifecycle - 1점', '보안 - 1점', '저장위치 - 2점', '속도...</td>\n      <td>['보안 - 1점', '저장위치 - 2점', '속도 - 1점']</td>\n      <td>mjw8523@gmail.com</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>recXfKthnQLwWETgb</td>\n      <td>[네트워크 1] 쿠키와 세션의 차이점을 설명해주세요.</td>\n      <td>jack</td>\n      <td>쿠키와 세션의 가장 큰 차이점은 정보가 저장되는 위치입니다. 쿠키는 서버의 자원을 ...</td>\n      <td>['세션이 쿠키보다 보안에 유리하다는 내용 - 1점', '세션이 쿠키보다 속도가 느...</td>\n      <td>['세션이 쿠키보다 보안에 유리하다는 내용 - 1점', '세션이 쿠키보다 속도가 느...</td>\n      <td>['Lifecycle - 1점', '보안 - 1점', '저장위치 - 2점', '속도...</td>\n      <td>['보안 - 1점', '저장위치 - 2점', '속도 - 1점']</td>\n      <td>mjw8523@gmail.com</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>recXfKthnQLwWETgb</td>\n      <td>[네트워크 1] 쿠키와 세션의 차이점을 설명해주세요.</td>\n      <td>jack</td>\n      <td>쿠키는 클라이언트 로컬에 저장되기 때문에 변질되거나 request에서 스니핑 당할 ...</td>\n      <td>['세션이 쿠키보다 보안에 유리하다는 내용 - 1점', '세션이 쿠키보다 속도가 느...</td>\n      <td>['세션이 쿠키보다 보안에 유리하다는 내용 - 1점', '저장위치가 쿠키는 클라이언...</td>\n      <td>['Lifecycle - 1점', '보안 - 1점', '저장위치 - 2점', '속도...</td>\n      <td>['보안 - 1점', '저장위치 - 2점']</td>\n      <td>mjw8523@gmail.com</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>recXfKthnQLwWETgb</td>\n      <td>[네트워크 1] 쿠키와 세션의 차이점을 설명해주세요.</td>\n      <td>jack</td>\n      <td>쿠키도 만료시간이 있지만 파일로 저장되기 때문에 브라우저를 종료해도 계속해서 정보가...</td>\n      <td>['세션이 쿠키보다 보안에 유리하다는 내용 - 1점', '세션이 쿠키보다 속도가 느...</td>\n      <td>['Lifecycle에 대한 내용 - 1점']</td>\n      <td>['Lifecycle - 1점', '보안 - 1점', '저장위치 - 2점', '속도...</td>\n      <td>['Lifecycle - 1점']</td>\n      <td>mjw8523@gmail.com</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>445</th>\n      <td>recUcGjT9Xkb7N5pu</td>\n      <td>[자료구조 3] Queue의 특징을 설명해주세요.</td>\n      <td>kshired</td>\n      <td>데이터가 삽입된 순서대로 삭제되는 선입선출(FIFO, First-In-First-O...</td>\n      <td>['rear에서 자료의 삽입이 front에서 자료의 삭제가 이루어짐 - 1점', '...</td>\n      <td>['rear에서 자료의 삽입이 front에서 자료의 삭제가 이루어짐 - 1점', '...</td>\n      <td>['시간복잡도 - 1점', 'FIFO - 2점', '삭제(POP) - 1점', '삽...</td>\n      <td>['시간복잡도 - 1점', 'FIFO - 2점', '삭제(POP) - 1점', '삽...</td>\n      <td>mjw8523@gmail.com</td>\n    </tr>\n    <tr>\n      <th>446</th>\n      <td>recUcGjT9Xkb7N5pu</td>\n      <td>[자료구조 3] Queue의 특징을 설명해주세요.</td>\n      <td>kshired</td>\n      <td>선입선출(FIFO, First in first out) 방식의 자료구조를 말한다. ...</td>\n      <td>['rear에서 자료의 삽입이 front에서 자료의 삭제가 이루어짐 - 1점', '...</td>\n      <td>['rear에서 자료의 삽입이 front에서 자료의 삭제가 이루어짐 - 1점', '...</td>\n      <td>['시간복잡도 - 1점', 'FIFO - 2점', '삭제(POP) - 1점', '삽...</td>\n      <td>['FIFO - 2점', '삭제(POP) - 1점', '삽입(PUSH) - 1점']</td>\n      <td>mjw8523@gmail.com</td>\n    </tr>\n    <tr>\n      <th>447</th>\n      <td>recUcGjT9Xkb7N5pu</td>\n      <td>[자료구조 3] Queue의 특징을 설명해주세요.</td>\n      <td>kshired</td>\n      <td>큐는 스택 자료구조와 달리 FIFO (First-In First-Out)- 선입 선...</td>\n      <td>['rear에서 자료의 삽입이 front에서 자료의 삭제가 이루어짐 - 1점', '...</td>\n      <td>['rear에서 자료의 삽입이 front에서 자료의 삭제가 이루어짐 - 1점', '...</td>\n      <td>['시간복잡도 - 1점', 'FIFO - 2점', '삭제(POP) - 1점', '삽...</td>\n      <td>['FIFO - 2점', '삭제(POP) - 1점', '삽입(PUSH) - 1점']</td>\n      <td>mjw8523@gmail.com</td>\n    </tr>\n    <tr>\n      <th>448</th>\n      <td>recUcGjT9Xkb7N5pu</td>\n      <td>[자료구조 3] Queue의 특징을 설명해주세요.</td>\n      <td>kshired</td>\n      <td>큐(Queue)는 FIFO(First In First Out) 의 특징을 갖는 자료...</td>\n      <td>['rear에서 자료의 삽입이 front에서 자료의 삭제가 이루어짐 - 1점', '...</td>\n      <td>['rear에서 자료의 삽입이 front에서 자료의 삭제가 이루어짐 - 1점', '...</td>\n      <td>['시간복잡도 - 1점', 'FIFO - 2점', '삭제(POP) - 1점', '삽...</td>\n      <td>['FIFO - 2점', '삭제(POP) - 1점', '삽입(PUSH) - 1점']</td>\n      <td>mjw8523@gmail.com</td>\n    </tr>\n    <tr>\n      <th>449</th>\n      <td>recUcGjT9Xkb7N5pu</td>\n      <td>[자료구조 3] Queue의 특징을 설명해주세요.</td>\n      <td>kshired</td>\n      <td>선입선출(FIFO, First in first out) 방식의 자료구조를 말한다. ...</td>\n      <td>['rear에서 자료의 삽입이 front에서 자료의 삭제가 이루어짐 - 1점', '...</td>\n      <td>['rear에서 자료의 삽입이 front에서 자료의 삭제가 이루어짐 - 1점', '...</td>\n      <td>['시간복잡도 - 1점', 'FIFO - 2점', '삭제(POP) - 1점', '삽...</td>\n      <td>['FIFO - 2점', '삭제(POP) - 1점', '삽입(PUSH) - 1점']</td>\n      <td>mjw8523@gmail.com</td>\n    </tr>\n  </tbody>\n</table>\n<p>450 rows × 9 columns</p>\n</div>"
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "outputs": [
    {
     "data": {
      "text/plain": "problem_id                                                   recXfKthnQLwWETgb\nproblem                                          [네트워크 1] 쿠키와 세션의 차이점을 설명해주세요.\nassign                                                                    jack\nuser_answer                  쿠키는 개인 PC에 text로 저장된다. 세션은 접속중인 웹 서버에 Object로 ...\nscoring_criterion            ['세션이 쿠키보다 보안에 유리하다는 내용 - 1점', '세션이 쿠키보다 속도가 느...\ncorrect_scoring_criterion    ['세션이 쿠키보다 속도가 느리다는 내용 - 1점', '저장위치가 쿠키는 클라이언트...\nkeyword_criterion            ['Lifecycle - 1점', '보안 - 1점', '저장위치 - 2점', '속도...\ncorrect_keyword_criterion                             ['저장위치 - 2점', '속도 - 1점']\nannotator                                                    mjw8523@gmail.com\nName: 0, dtype: object"
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre data size : 450\n",
      "after data size : 449\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# NAN data 제거\n",
    "print(f\"pre data size : {len(df)}\")\n",
    "df['user_answer'] = df['user_answer'].str.strip().str.replace(\"\\n\", \"\").str.replace(\"\\xa0\", \"\").str.replace(\"  \", \" \")\n",
    "df['user_answer'].replace('', np.nan, inplace=True)\n",
    "df.dropna(axis=0, subset=['user_answer'], inplace=True)  # 빈 답변 제거\n",
    "print(f\"after data size : {len(df)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "가장 긴 답변 489ch:\n",
      "\t 각 행마다 행을 식별할 수 있도록 전부 다른 값이 저장된 열을 찾으셨다면, 그 열을 가지고 기본 키를 만들 수 있습니다. 다시 한번 강조하자면, 기본 키는 테이블 내의 각 행을 고유하게 하는 열입니다. 고로, 기본 키는 모든 행이 고유한 값을 가지고 있는지 혹은 값이 비어있는 행이 있는지 확인할 수 있도록 합니다. 예를 들어, 여러분이 이미 어떤 열에 존재하는 값을 새로운 행을 만들어서 추가하고자 한다면, 이는 기본 키에 의해서 생성이 제한됩니다. 또한, 기본 키는 NULL 값을 받아들이지 않습니다. 즉, 기본 키 열에는 NULL 값이 존재할 수 없습니다. 미국 시민의 정보를 저장하고 있는 테이블인 citizen 예시가 기억나십니까? 만약 social_security_number 열에 NULL 값이 포함된 행을 추가하고자 한다면, 이는 기본 키에 의해서 제지 당합니다. 다시 말해서, 기본 키는 기본 키가 되는 열의 행 값이 고유하고 비어있지 않도록 만들어 줍니다.\n",
      "가장 짧은 답변 13ch:\n",
      "\t 원자성, 일관성이 있다.\n"
     ]
    }
   ],
   "source": [
    "min_len = min(map(len, df['user_answer']))\n",
    "max_len = max(map(len, df['user_answer']))\n",
    "\n",
    "for i, data in df.iterrows():\n",
    "    if len(data['user_answer']) == min_len:\n",
    "        print(f\"가장 짧은 답변 {min_len}ch:\\n\\t {data['user_answer']}\")\n",
    "    elif len(data['user_answer']) == max_len:\n",
    "        print(f\"가장 긴 답변 {max_len}ch:\\n\\t {data['user_answer']}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### pip install konlpy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt\n",
    "okt = Okt()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import List\n",
    "\n",
    "@dataclass\n",
    "class Problem:\n",
    "    subject: str  # 문제별\n",
    "    keywords: List[str]  # 문제별\n",
    "    keywords_score: List[int]  # 문제별\n",
    "    keywords_embedding : List[np.ndarray]  # 문제별\n",
    "    user_answers: List[str]  # 유저별\n",
    "    user_correct_keywords: List[List[str]]  # 유저별\n",
    "    ground_truths: List[List[int]]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "outputs": [
    {
     "data": {
      "text/plain": "problem_id                                                   recXfKthnQLwWETgb\nproblem                                          [네트워크 1] 쿠키와 세션의 차이점을 설명해주세요.\nassign                                                                    jack\nuser_answer                  쿠키는 개인 PC에 text로 저장된다. 세션은 접속중인 웹 서버에 Object로 ...\nscoring_criterion            ['세션이 쿠키보다 보안에 유리하다는 내용 - 1점', '세션이 쿠키보다 속도가 느...\ncorrect_scoring_criterion    ['세션이 쿠키보다 속도가 느리다는 내용 - 1점', '저장위치가 쿠키는 클라이언트...\nkeyword_criterion            ['Lifecycle - 1점', '보안 - 1점', '저장위치 - 2점', '속도...\ncorrect_keyword_criterion                             ['저장위치 - 2점', '속도 - 1점']\nannotator                                                    mjw8523@gmail.com\nName: 0, dtype: object"
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "outputs": [],
   "source": [
    "dataset = {}\n",
    "# criterion parsing\n",
    "for i, data in df.iterrows():\n",
    "    problem_id = data['problem_id']\n",
    "    if problem_id not in dataset:\n",
    "        keywords = []\n",
    "        keywords_score = []\n",
    "\n",
    "        for criterion in eval(data['keyword_criterion']):\n",
    "            keyword, score = map(str.strip, criterion.split('-'))\n",
    "            score = float(score.split(\"점\")[0])\n",
    "            keywords.append(keyword)\n",
    "            keywords_score.append(score)\n",
    "        keywords_embedding = model.encode(keywords)\n",
    "\n",
    "        dataset[problem_id] = Problem(\n",
    "            subject=data['problem'],\n",
    "            keywords=keywords,\n",
    "            keywords_score=keywords_score,\n",
    "            keywords_embedding=keywords_embedding,\n",
    "            user_answers=[],\n",
    "            user_correct_keywords=[],\n",
    "            ground_truths=[],\n",
    "        )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "problem : [네트워크 2] HTTP 메서드의 멱등성에 대해서 설명해주세요.\n",
      "keywords : ['POST', '동일한 요청', 'stateless']\n",
      "keyword embedding shape :(3, 768)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "problem_id = random.choice(list(dataset.keys()))\n",
    "print(f\"problem : {dataset[problem_id].subject}\")\n",
    "print(f\"keywords : {dataset[problem_id].keywords}\")\n",
    "print(f\"keyword embedding shape :{dataset[problem_id].keywords_embedding.shape}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 1, 1]\n",
      "[0, 1, 1, 1]\n",
      "[0, 1, 1, 1]\n",
      "[0, 1, 1, 0]\n",
      "[1, 0, 0, 0]\n",
      "[0, 0, 0, 1]\n",
      "[0, 0, 1, 0]\n",
      "[0, 0, 1, 0]\n",
      "[1, 0, 0, 0]\n",
      "[0, 1, 1, 0]\n",
      "[0, 0, 1, 0]\n",
      "[1, 1, 1, 1]\n",
      "[0, 0, 1, 0]\n",
      "[0, 0, 1, 0]\n",
      "[1, 1, 1, 0]\n",
      "[0, 1, 1, 0]\n",
      "[0, 1, 1, 1]\n",
      "[0, 1, 1, 0]\n",
      "[1, 0, 0, 0]\n",
      "[0, 0, 0, 1]\n",
      "[0, 1, 0]\n",
      "[0, 1, 0]\n",
      "[0, 0, 1]\n",
      "[0, 1, 1]\n",
      "[0, 1, 1]\n",
      "[1, 0, 0]\n",
      "[0, 1, 1]\n",
      "[1, 1, 1]\n",
      "[0, 1, 1]\n",
      "[1, 1, 0]\n",
      "[0, 1, 0]\n",
      "[0, 1, 0]\n",
      "[0, 1, 1]\n",
      "[1, 1, 0]\n",
      "[0, 1, 1]\n",
      "[0, 1, 0]\n",
      "[0, 0, 0]\n",
      "[0, 0, 0]\n",
      "[0, 1, 0]\n",
      "[1, 0, 0]\n",
      "[0, 0, 1]\n",
      "[1, 0, 1]\n",
      "[0, 0, 1]\n",
      "[1, 0, 1]\n",
      "[0, 0, 0]\n",
      "[0, 0, 1]\n",
      "[1, 1, 0]\n",
      "[0, 0, 1]\n",
      "[0, 1, 1]\n",
      "[1, 1, 1]\n",
      "[0, 1, 1]\n",
      "[0, 0, 0]\n",
      "[1, 0, 1]\n",
      "[0, 0, 0]\n",
      "[0, 0, 1]\n",
      "[0, 0, 1]\n",
      "[0, 0, 0]\n",
      "[0, 0, 1]\n",
      "[0, 1, 0]\n",
      "[1, 1, 0]\n",
      "[1, 1, 1, 1]\n",
      "[1, 1, 1, 1]\n",
      "[1, 1, 1, 1]\n",
      "[1, 1, 1, 1]\n",
      "[1, 1, 1, 1]\n",
      "[0, 0, 0, 0]\n",
      "[1, 1, 1, 1]\n",
      "[1, 1, 1, 1]\n",
      "[1, 1, 1, 1]\n",
      "[1, 1, 1, 1]\n",
      "[1, 1, 1, 1]\n",
      "[1, 1, 1, 1]\n",
      "[1, 1, 1, 1]\n",
      "[1, 1, 0, 1]\n",
      "[1, 1, 1, 1]\n",
      "[1, 1, 1, 1]\n",
      "[1, 1, 1, 1]\n",
      "[1, 1, 1, 1]\n",
      "[1, 1, 1, 1]\n",
      "[1, 1, 1, 1]\n",
      "[1, 1, 1, 1]\n",
      "[1, 1, 1, 1]\n",
      "[1, 1, 1, 1]\n",
      "[1, 1, 1, 1]\n",
      "[1, 1, 1, 1]\n",
      "[1, 1, 1, 1]\n",
      "[0, 0, 0, 0]\n",
      "[1, 1, 1, 1]\n",
      "[0, 0, 0, 0]\n",
      "[1, 1, 1, 1]\n",
      "[1, 1, 1, 1]\n",
      "[1, 1, 1, 1]\n",
      "[1, 1, 1, 1]\n",
      "[0, 0, 0, 0]\n",
      "[0, 1, 0, 0]\n",
      "[0, 0, 0, 0]\n",
      "[1, 1, 1, 1]\n",
      "[1, 1, 1, 1]\n",
      "[1, 1, 1, 1]\n",
      "[0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 1]\n",
      "[0, 0, 1, 0, 1]\n",
      "[1, 0, 1, 0, 1]\n",
      "[0, 1, 0, 0, 0]\n",
      "[0, 0, 1, 0, 1]\n",
      "[0, 0, 1, 0, 0]\n",
      "[0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0]\n",
      "[1, 0, 1, 0, 0]\n",
      "[0, 0, 0, 0, 0]\n",
      "[1, 0, 1, 0, 0]\n",
      "[0, 0, 1, 0, 1]\n",
      "[0, 0, 0, 0, 1]\n",
      "[0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 1, 1]\n",
      "[0, 0, 1, 0, 0]\n",
      "[0, 1, 0, 0, 0]\n",
      "[0, 1, 1, 0]\n",
      "[0, 1, 0]\n",
      "[0, 0, 1, 0, 0]\n",
      "[0, 0, 0, 0]\n",
      "[0, 0, 0, 0]\n",
      "[0, 1, 1]\n",
      "[0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0]\n",
      "[0, 0, 1, 0]\n",
      "[1, 1, 0]\n",
      "[1, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0]\n",
      "[0, 1, 1, 0]\n",
      "[1, 1, 0]\n",
      "[0, 0, 0, 0, 0]\n",
      "[0, 0, 1, 0]\n",
      "[1, 0, 1, 0]\n",
      "[0, 1, 1]\n",
      "[0, 0, 0, 0, 0]\n",
      "[1, 1, 1, 1]\n",
      "[0, 0, 1, 1]\n",
      "[0, 0, 1]\n",
      "[0, 0, 0, 0, 0]\n",
      "[1, 1, 0, 1]\n",
      "[0, 1, 1, 0]\n",
      "[0, 1, 1]\n",
      "[0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0]\n",
      "[1, 0, 0, 0]\n",
      "[1, 1, 1]\n",
      "[0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0]\n",
      "[1, 0, 1, 1]\n",
      "[1, 1, 1]\n",
      "[0, 1, 1, 0, 0]\n",
      "[0, 0, 0, 0]\n",
      "[0, 0, 1, 0]\n",
      "[0, 1, 0]\n",
      "[0, 0, 0, 0, 1]\n",
      "[0, 0, 0, 0]\n",
      "[0, 0, 1, 0]\n",
      "[0, 0, 0]\n",
      "[0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0]\n",
      "[0, 1, 0, 0]\n",
      "[0, 1, 1]\n",
      "[0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0]\n",
      "[1, 0, 0, 0]\n",
      "[1, 0, 0]\n",
      "[0, 0, 0, 0, 1]\n",
      "[1, 1, 1, 1]\n",
      "[0, 0, 1, 1]\n",
      "[0, 0, 0]\n",
      "[0, 0, 0, 0, 0]\n",
      "[1, 1, 0, 0]\n",
      "[0, 1, 1, 1]\n",
      "[0, 1, 0]\n",
      "[0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0]\n",
      "[0, 0, 1, 0]\n",
      "[1, 1, 0]\n",
      "[0, 0, 0, 0, 1]\n",
      "[0, 0, 0, 0]\n",
      "[0, 0, 1, 0]\n",
      "[0, 0, 0]\n",
      "[0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0]\n",
      "[1, 0, 1, 0]\n",
      "[0, 1, 0]\n",
      "[0, 1, 1, 0, 0]\n",
      "[1, 1, 1, 1]\n",
      "[1, 1, 1, 1]\n",
      "[1, 1, 0]\n",
      "[0, 0, 0, 0, 0]\n",
      "[1, 1, 1, 1]\n",
      "[0, 0, 1, 0]\n",
      "[1, 1, 0]\n",
      "[0, 0, 1, 0, 0]\n",
      "[1, 1, 1, 1]\n",
      "[0, 0, 1, 0]\n",
      "[0, 0, 1]\n",
      "[0, 0, 0, 0, 0]\n",
      "[1, 1, 1, 1]\n",
      "[0, 0, 1, 1]\n",
      "[1, 1, 0]\n",
      "[0, 0, 1, 0, 0]\n",
      "[0, 1, 0, 0]\n",
      "[0, 0, 1, 0]\n",
      "[0, 0, 0]\n",
      "[0, 0, 0, 0, 0]\n",
      "[1, 1, 1, 1]\n",
      "[0, 0, 1, 1]\n",
      "[1, 1, 0]\n",
      "[0, 0, 0, 0, 0]\n",
      "[1, 1, 1, 1]\n",
      "[0, 1, 1, 1]\n",
      "[1, 1, 0]\n",
      "[0, 0, 1, 0, 0]\n",
      "[1, 1, 1, 1]\n",
      "[0, 0, 1]\n",
      "[1, 1, 1, 1]\n",
      "[0, 0, 1]\n",
      "[1, 1, 0, 1]\n",
      "[1, 0, 1]\n",
      "[0, 1, 1, 1]\n",
      "[0, 0, 1]\n",
      "[1, 0, 1, 1]\n",
      "[0, 0, 0]\n",
      "[1, 1, 0, 1]\n",
      "[0, 1, 0]\n",
      "[1, 1, 1, 0]\n",
      "[1, 0, 1]\n",
      "[1, 0, 0, 1]\n",
      "[1, 1, 1]\n",
      "[1, 0, 1, 0]\n",
      "[1, 1, 1]\n",
      "[1, 1, 1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1, 1, 1]\n",
      "[0, 0, 1]\n",
      "[1, 1, 1, 1]\n",
      "[1, 1, 0]\n",
      "[0, 1, 0, 1]\n",
      "[0, 1, 1]\n",
      "[1, 1, 1, 1]\n",
      "[0, 1, 1]\n",
      "[1, 1, 1, 0]\n",
      "[1, 0, 1]\n",
      "[1, 0, 1, 1]\n",
      "[0, 0, 1]\n",
      "[1, 1, 0, 1]\n",
      "[1, 1, 1]\n",
      "[1, 0, 1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1, 1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1, 1, 1]\n",
      "[0, 0, 1]\n",
      "[1, 1, 0, 1]\n",
      "[0, 1, 1]\n",
      "[1, 1, 1, 1]\n",
      "[0, 1, 1]\n",
      "[1, 0, 0, 1]\n",
      "[0, 1, 1]\n",
      "[1, 1, 1, 1]\n",
      "[1, 1, 0]\n",
      "[1, 1, 1, 1]\n",
      "[1, 1, 1]\n",
      "[1, 1, 1, 0]\n",
      "[1, 0, 0, 0, 0]\n",
      "[1, 0, 0, 0, 0]\n",
      "[1, 0, 0, 0, 0]\n",
      "[1, 0, 1, 1, 1]\n",
      "[1, 0, 1, 1, 1]\n",
      "[0, 0, 0, 0, 1]\n",
      "[0, 0, 0, 0, 1]\n",
      "[1, 0, 0, 0, 1]\n",
      "[1, 0, 0, 1, 0]\n",
      "[0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 1, 0]\n",
      "[0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 1, 1]\n",
      "[0, 0, 1, 1, 1]\n",
      "[0, 0, 1, 1, 1]\n",
      "[0, 0, 0, 0, 1]\n",
      "[0, 0, 0, 1, 0]\n",
      "[0, 0, 1, 1, 1]\n",
      "[0, 1, 0, 0, 1]\n",
      "[0, 0, 0, 1, 1]\n",
      "[1, 0, 0, 0, 0]\n",
      "[0, 0, 1, 0, 0]\n",
      "[0, 0, 1, 1, 1]\n",
      "[0, 0, 0, 0, 1]\n",
      "[0, 0, 0, 1, 0]\n",
      "[0, 0, 0, 0, 1]\n",
      "[0, 0, 1, 1, 1]\n",
      "[0, 1, 0, 0, 0]\n",
      "[1, 0, 0, 1, 0]\n",
      "[0, 0, 1, 1, 1]\n",
      "[0, 0, 1, 1, 1]\n",
      "[0, 0, 0, 1, 1]\n",
      "[0, 0, 0, 1, 1]\n",
      "[0, 0, 1, 0, 1]\n",
      "[0, 1, 1, 1, 0]\n",
      "[0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 1, 1]\n",
      "[0, 0, 0, 0, 0]\n",
      "[0, 0, 1, 0, 0]\n",
      "[1, 0, 1, 1, 1]\n",
      "[0, 0, 1, 1, 1]\n",
      "[0, 1, 0, 1, 0]\n",
      "[0, 0, 1, 0]\n",
      "[1, 1, 1, 1]\n",
      "[1, 0, 0, 1]\n",
      "[1, 0, 0, 0]\n",
      "[0, 0, 1, 0]\n",
      "[0, 0, 1, 0]\n",
      "[0, 1, 0, 0]\n",
      "[1, 0, 0, 0]\n",
      "[1, 0, 1, 0]\n",
      "[0, 0, 1, 0]\n",
      "[0, 1, 0, 0]\n",
      "[0, 0, 0, 0]\n",
      "[0, 0, 0, 0]\n",
      "[1, 0, 0, 0]\n",
      "[0, 0, 1, 0]\n",
      "[1, 0, 0, 0]\n",
      "[0, 0, 0, 0]\n",
      "[0, 1, 1, 0]\n",
      "[0, 0, 1, 0]\n",
      "[0, 1, 1, 0]\n",
      "[1, 0, 0, 0]\n",
      "[1, 0, 0, 1]\n",
      "[1, 0, 0, 1]\n",
      "[0, 0, 0, 0]\n",
      "[0, 0, 0, 1]\n",
      "[1, 0, 0, 1]\n",
      "[1, 0, 1, 1]\n",
      "[0, 1, 1, 0]\n",
      "[1, 0, 1, 0]\n",
      "[1, 1, 0, 0]\n",
      "[0, 0, 1, 0]\n",
      "[1, 1, 1, 1]\n",
      "[1, 1, 1, 1]\n",
      "[1, 0, 0, 0]\n",
      "[0, 0, 0, 0]\n",
      "[0, 0, 0, 1]\n",
      "[1, 1, 1, 0]\n",
      "[0, 0, 0, 1]\n",
      "[1, 0, 0, 0]\n",
      "[1, 0, 0, 1]\n",
      "[1, 0, 1, 1]\n",
      "[0, 0, 0, 1]\n",
      "[1, 0, 1, 1]\n",
      "[1, 0, 1, 1]\n",
      "[1, 1, 1, 1]\n",
      "[1, 0, 1, 1]\n",
      "[1, 0, 0, 1]\n",
      "[1, 0, 0, 1]\n",
      "[1, 0, 1, 1]\n",
      "[1, 0, 1, 1]\n",
      "[1, 0, 1, 1]\n",
      "[1, 0, 1, 1]\n",
      "[1, 0, 1, 1]\n",
      "[1, 0, 1, 1]\n",
      "[1, 0, 1, 1]\n",
      "[1, 0, 1, 1]\n",
      "[1, 0, 1, 1]\n",
      "[1, 0, 1, 1]\n",
      "[0, 0, 1, 1]\n",
      "[1, 0, 1, 1]\n",
      "[1, 0, 1, 1]\n",
      "[1, 0, 1, 1]\n",
      "[1, 0, 1, 1]\n",
      "[0, 0, 0, 1]\n",
      "[1, 0, 1, 1]\n",
      "[1, 1, 1, 1]\n",
      "[1, 1, 1, 1]\n",
      "[1, 1, 1, 1]\n",
      "[1, 0, 1, 0]\n",
      "[1, 0, 1, 0]\n",
      "[1, 0, 1, 1]\n",
      "[1, 0, 1, 1]\n",
      "[1, 1, 1, 1]\n",
      "[1, 1, 1, 0]\n",
      "[1, 1, 1, 1]\n",
      "[1, 1, 1, 1]\n",
      "[1, 0, 1, 1]\n",
      "[1, 1, 1, 1]\n",
      "[1, 0, 1, 1]\n",
      "[1, 0, 1, 1]\n",
      "[1, 0, 1, 1]\n",
      "[1, 1, 1, 1]\n",
      "[1, 1, 1, 1]\n",
      "[1, 1, 1, 1]\n",
      "[0, 0, 0, 1]\n",
      "[1, 1, 1, 1]\n",
      "[0, 0, 0, 1]\n",
      "[1, 0, 1, 1]\n",
      "[1, 0, 1, 1]\n",
      "[0, 1, 1, 1]\n",
      "[0, 1, 1, 1]\n",
      "[0, 1, 0, 0]\n",
      "[0, 1, 1, 1]\n",
      "[0, 1, 1, 1]\n",
      "[0, 1, 1, 1]\n",
      "[0, 1, 1, 1]\n",
      "[0, 1, 1, 1]\n",
      "[0, 1, 1, 1]\n",
      "[0, 1, 1, 1]\n",
      "[0, 1, 1, 1]\n",
      "[0, 1, 0, 0]\n",
      "[0, 1, 1, 1]\n",
      "[0, 1, 0, 0]\n",
      "[0, 1, 0, 0]\n",
      "[0, 1, 1, 1]\n",
      "[0, 1, 0, 0]\n",
      "[0, 1, 1, 1]\n",
      "[1, 1, 1, 1]\n",
      "[0, 1, 1, 1]\n",
      "[1, 1, 1, 1]\n",
      "[0, 1, 1, 1]\n",
      "[0, 1, 1, 1]\n",
      "[0, 0, 1, 1]\n",
      "[0, 1, 1, 1]\n",
      "[1, 1, 1, 1]\n",
      "[0, 1, 1, 1]\n",
      "[0, 0, 1, 1]\n",
      "[0, 0, 1, 1]\n",
      "[0, 1, 1, 1]\n",
      "[1, 1, 1, 1]\n",
      "[0, 1, 1, 1]\n",
      "[0, 0, 0, 0]\n",
      "[0, 1, 1, 1]\n",
      "[0, 0, 1, 1]\n",
      "[0, 1, 1, 1]\n",
      "[0, 1, 1, 1]\n",
      "[0, 1, 0, 0]\n",
      "[1, 1, 1, 1]\n",
      "[1, 1, 1, 1]\n",
      "[1, 1, 1, 1]\n",
      "[0, 1, 1, 1]\n",
      "[0, 1, 1, 1]\n",
      "[0, 1, 1, 1]\n",
      "[0, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "for i, data in df.iterrows():\n",
    "    problem = dataset[data['problem_id']]\n",
    "    user_answer = data['user_answer']\n",
    "    user_correct_keyword = [criterion.split('-')[0].rstrip() for criterion in eval(data['correct_keyword_criterion'])]\n",
    "    ground_truth = [1 if keyword in user_correct_keyword else 0 for keyword in problem.keywords]\n",
    "    problem.user_correct_keywords.append(user_correct_keyword)\n",
    "    problem.user_answers.append(user_answer)\n",
    "    problem.ground_truths.append(ground_truth)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "outputs": [],
   "source": [
    "# for problem_id in dataset:\n",
    "#     problem = dataset[problem_id]\n",
    "#     for gt, correct_keyword in zip(problem.ground_truths, problem.user_correct_keywords):\n",
    "#         ground_truth = []\n",
    "#         for i, flag in enumerate(gt):\n",
    "#             if flag:\n",
    "#                 ground_truth.append(problem.keywords[i])\n",
    "#         if not ground_truth == correct_keyword:\n",
    "#             print(ground_truth, correct_keyword)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[네트워크 1] 쿠키와 세션의 차이점을 설명해주세요.\n",
      "45개의 유저 답변\n",
      "45개의 유저의 답변별 키워드 라벨링\n",
      "[네트워크 2] HTTP 메서드의 멱등성에 대해서 설명해주세요.\n",
      "45개의 유저 답변\n",
      "45개의 유저의 답변별 키워드 라벨링\n",
      "[자료구조 1] Array의 특징을 설명해주세요.\n",
      "45개의 유저 답변\n",
      "45개의 유저의 답변별 키워드 라벨링\n",
      "[데이터베이스 2] Transaction의 네가지 특성을 설명해주세요.\n",
      "45개의 유저 답변\n",
      "45개의 유저의 답변별 키워드 라벨링\n",
      "[운영체제 1] Deadlock의 발생조건 네가지를 간단히 설명해주세요.\n",
      "45개의 유저 답변\n",
      "45개의 유저의 답변별 키워드 라벨링\n",
      "[데이터베이스 1] Primary key가 무엇인지 설명해주세요.\n",
      "45개의 유저 답변\n",
      "45개의 유저의 답변별 키워드 라벨링\n",
      "[운영체제 2] 프로세스와 스레드의 차이점을 설명해주세요.\n",
      "45개의 유저 답변\n",
      "45개의 유저의 답변별 키워드 라벨링\n",
      "[데이터베이스 3] DB Index를 어떤 특징을 가진 column에 사용하면 좋을지 설명해주세요.\n",
      "45개의 유저 답변\n",
      "45개의 유저의 답변별 키워드 라벨링\n",
      "[자료구조 2] Stack의 특징을 설명해주세요.\n",
      "44개의 유저 답변\n",
      "44개의 유저의 답변별 키워드 라벨링\n",
      "[자료구조 3] Queue의 특징을 설명해주세요.\n",
      "45개의 유저 답변\n",
      "45개의 유저의 답변별 키워드 라벨링\n"
     ]
    }
   ],
   "source": [
    "for problem_id in dataset:\n",
    "    print(f\"{dataset[problem_id].subject}\")\n",
    "    print(f\"{len(dataset[problem_id].user_answers)}개의 유저 답변\")\n",
    "    print(f\"{len(dataset[problem_id].user_correct_keywords)}개의 유저의 답변별 키워드 라벨링\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45it [00:13,  3.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0번 문제 점수 : accuracy : 0.8666666666666667, f1-score : 0.7817989417989418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45it [00:11,  3.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1번 문제 점수 : accuracy : 0.5185185185185184, f1-score : 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45it [00:13,  3.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2번 문제 점수 : accuracy : 0.5185185185185184, f1-score : 0.10370370370370369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45it [00:20,  2.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3번 문제 점수 : accuracy : 0.5055555555555555, f1-score : 0.5707936507936509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45it [00:14,  3.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4번 문제 점수 : accuracy : 0.8277777777777777, f1-score : 0.5485714285714286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45it [00:10,  4.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5번 문제 점수 : accuracy : 0.8888888888888887, f1-score : 0.22518518518518518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45it [00:11,  3.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6번 문제 점수 : accuracy : 0.8622222222222223, f1-score : 0.5651851851851852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45it [00:13,  3.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7번 문제 점수 : accuracy : 0.7611111111111111, f1-score : 0.4087830687830688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "44it [00:12,  3.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8번 문제 점수 : accuracy : 0.6136363636363636, f1-score : 0.527813852813853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45it [00:11,  3.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9번 문제 점수 : accuracy : 0.3277777777777778, f1-score : 0.017777777777777778\n",
      "전체 문제 평균 accuracy : 0.6690673400673399, f1-score : 0.37496127946127944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 유사도 검사\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tqdm import tqdm\n",
    "\n",
    "threshold = 0.7\n",
    "total_acc, total_f1 = 0, 0\n",
    "for i, key in enumerate(dataset):\n",
    "    acc, f1 = 0, 0\n",
    "    problem = dataset[key]\n",
    "    for j, (user_answer, ground_truth) in enumerate(tqdm(zip(problem.user_answers, problem.ground_truths))):\n",
    "        tokenized_answer = [word[0] for word in okt.pos(user_answer) if word[1] == 'Noun']  # 명사만 추출\n",
    "        tokenized_answer_embedding = model.encode(tokenized_answer)\n",
    "        similarity_scores = cosine_similarity(problem.keywords_embedding, tokenized_answer_embedding)\n",
    "        predicts = [1 if score.max() > 0.7 else 0 for idx, score in enumerate(similarity_scores)]\n",
    "        acc += accuracy_score(ground_truth, predicts)\n",
    "        f1 += f1_score(ground_truth, predicts, zero_division=0)\n",
    "    print(f\"{i}번 문제 점수 : accuracy : {acc / len(problem.user_answers)}, f1-score : {f1 / len(problem.user_answers)}\")\n",
    "    total_acc += acc / len(problem.user_answers)\n",
    "    total_f1 += f1 / len(problem.user_answers)\n",
    "print(f\"전체 문제 평균 accuracy : {total_acc / len(dataset)}, f1-score : {total_f1 / len(dataset)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45it [00:19,  2.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0번 문제 점수 : accuracy : 0.8777777777777778, f1-score : 0.7881481481481482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45it [00:17,  2.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1번 문제 점수 : accuracy : 0.6074074074074075, f1-score : 0.18148148148148152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45it [00:19,  2.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2번 문제 점수 : accuracy : 0.5185185185185184, f1-score : 0.10370370370370369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45it [00:27,  1.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3번 문제 점수 : accuracy : 0.5055555555555555, f1-score : 0.5707936507936509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45it [00:16,  2.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4번 문제 점수 : accuracy : 0.8277777777777777, f1-score : 0.5485714285714286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45it [00:12,  3.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5번 문제 점수 : accuracy : 0.8888888888888887, f1-score : 0.22518518518518518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45it [00:14,  3.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6번 문제 점수 : accuracy : 0.8977777777777778, f1-score : 0.6183068783068784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45it [00:12,  3.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7번 문제 점수 : accuracy : 0.7611111111111111, f1-score : 0.4087830687830688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "44it [00:19,  2.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8번 문제 점수 : accuracy : 0.8068181818181818, f1-score : 0.8030303030303031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45it [00:17,  2.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9번 문제 점수 : accuracy : 0.5222222222222223, f1-score : 0.437037037037037\n",
      "전체 문제 평균 accuracy : 0.7213855218855219, f1-score : 0.4685040885040885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 유사도 검사 -> 영어도 추가\n",
    "threshold = 0.7\n",
    "total_acc, total_f1 = 0, 0\n",
    "for i, key in enumerate(dataset):\n",
    "    acc, f1 = 0, 0\n",
    "    problem = dataset[key]\n",
    "    for j, (user_answer, ground_truth) in enumerate(tqdm(zip(problem.user_answers, problem.ground_truths))):\n",
    "        tokenized_answer = [word[0] for word in okt.pos(user_answer) if word[1] in ('Noun', 'Alpha')]  # 명사만 추출\n",
    "        tokenized_answer_embedding = model.encode(tokenized_answer)\n",
    "        similarity_scores = cosine_similarity(problem.keywords_embedding, tokenized_answer_embedding)\n",
    "        predicts = [1 if score.max() > 0.7 else 0 for idx, score in enumerate(similarity_scores)]\n",
    "        acc += accuracy_score(ground_truth, predicts)\n",
    "        f1 += f1_score(ground_truth, predicts, zero_division=0)\n",
    "    print(f\"{i}번 문제 점수 : accuracy : {acc / len(problem.user_answers)}, f1-score : {f1 / len(problem.user_answers)}\")\n",
    "    total_acc += acc / len(problem.user_answers)\n",
    "    total_f1 += f1 / len(problem.user_answers)\n",
    "print(f\"전체 문제 평균 accuracy : {total_acc / len(dataset)}, f1-score : {total_f1 / len(dataset)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "### 2번이랑 3번이랑 아니 그냥 전체적으로 엉망진창이네!!\n",
    "### 성능 향상을 위한 방법들은 아래와 같다.\n",
    "- 동의어 직접 정의\n",
    "- Tokenizing을 하지 않고 n-gram 방식으로 대조\n",
    "- 불용어 제거\n",
    "---"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0번째 문제 ID : recXfKthnQLwWETgb\n",
      "0번째 문제 : [네트워크 1] 쿠키와 세션의 차이점을 설명해주세요.\n",
      "keyword : ['만료', '보안', '저장위치', '속도']\n",
      "1번째 문제 ID : recySzF3AcHS6Llfl\n",
      "1번째 문제 : [네트워크 2] HTTP 메서드의 멱등성에 대해서 설명해주세요.\n",
      "keyword : ['POST', '동일한 요청', 'stateless']\n",
      "2번째 문제 ID : reciNccHh7EP8mRwD\n",
      "2번째 문제 : [자료구조 1] Array의 특징을 설명해주세요.\n",
      "keyword : ['랜덤 액세스', '시간 복잡도', '저장 순서']\n",
      "3번째 문제 ID : recThdU8zcC6rL6fa\n",
      "3번째 문제 : [데이터베이스 2] Transaction의 네가지 특성을 설명해주세요.\n",
      "keyword : ['일관성', '독립성', '지속성', '원자성']\n",
      "4번째 문제 ID : recQWCxI7HfuXiYPO\n",
      "4번째 문제 : [운영체제 1] Deadlock의 발생조건 네가지를 간단히 설명해주세요.\n",
      "keyword : ['상호 배제', '점유 대기', '순환 대기', '비선점']\n",
      "5번째 문제 ID : recio3s0A77i0kkEn\n",
      "5번째 문제 : [데이터베이스 1] Primary key가 무엇인지 설명해주세요.\n",
      "keyword : ['최소성', '대표성', '유일성', '불변성', '식별자']\n",
      "6번째 문제 ID : rec1QvAvB4CMami3p\n",
      "6번째 문제 : [운영체제 2] 프로세스와 스레드의 차이점을 설명해주세요.\n",
      "keyword : ['작업단위', 'context switching', '스택', '메모리', '영역 공유']\n",
      "7번째 문제 ID : recvqnC3QKpHRbqYl\n",
      "7번째 문제 : [데이터베이스 3] DB Index를 어떤 특징을 가진 column에 사용하면 좋을지 설명해주세요.\n",
      "keyword : ['카디널리티', '수정 빈도', '조회 빈도', '선택도']\n",
      "8번째 문제 ID : recRLoltonwRHFxH8\n",
      "8번째 문제 : [자료구조 2] Stack의 특징을 설명해주세요.\n",
      "keyword : ['삭제', '시간복잡도', '삽입', 'LIFO']\n",
      "9번째 문제 ID : recUcGjT9Xkb7N5pu\n",
      "9번째 문제 : [자료구조 3] Queue의 특징을 설명해주세요.\n",
      "keyword : ['시간복잡도', 'FIFO', '삭제', '삽입']\n"
     ]
    }
   ],
   "source": [
    "for i, problem_id in enumerate(dataset):\n",
    "    problem = dataset[problem_id]\n",
    "    print(f\"{i}번째 문제 ID : {problem_id}\")\n",
    "    print(f\"{i}번째 문제 : {problem.subject}\")\n",
    "    print(f\"keyword : {problem.keywords}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "outputs": [],
   "source": [
    "dataset['recXfKthnQLwWETgb'].keywords[0] = \"만료\"  # Lifecycle -> 만료\n",
    "dataset['recXfKthnQLwWETgb'].keywords_embedding = model.encode(dataset['recXfKthnQLwWETgb'].keywords)  # 1번\n",
    "dataset['recUcGjT9Xkb7N5pu'].keywords[2] = \"삭제\"  # 삭제(POP) -> 삭제\n",
    "dataset['recUcGjT9Xkb7N5pu'].keywords[3] = \"삽입\"  # 삽입(PUSH) -> 삽입\n",
    "dataset['recUcGjT9Xkb7N5pu'].keywords_embedding = model.encode(dataset['recUcGjT9Xkb7N5pu'].keywords)  # 10번\n",
    "dataset['rec1QvAvB4CMami3p'].keywords[2] = '스택'  # 7\n",
    "dataset['rec1QvAvB4CMami3p'].keywords_embedding = model.encode(dataset['rec1QvAvB4CMami3p'].keywords)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45it [00:22,  1.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0번 문제 점수 : accuracy : 0.6555555555555556, f1-score : 0.2348148148148148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45it [00:22,  2.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1번 문제 점수 : accuracy : 0.6962962962962965, f1-score : 0.32814814814814813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45it [00:22,  2.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2번 문제 점수 : accuracy : 0.5851851851851851, f1-score : 0.2629629629629629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45it [00:29,  1.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3번 문제 점수 : accuracy : 0.5833333333333334, f1-score : 0.6411640211640214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45it [00:21,  2.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4번 문제 점수 : accuracy : 0.7944444444444444, f1-score : 0.4357671957671958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45it [00:14,  3.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5번 문제 점수 : accuracy : 0.8933333333333332, f1-score : 0.20740740740740743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45it [00:20,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6번 문제 점수 : accuracy : 0.7244444444444447, f1-score : 0.19925925925925927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45it [00:17,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7번 문제 점수 : accuracy : 0.6944444444444444, f1-score : 0.2647619047619048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "44it [00:26,  1.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8번 문제 점수 : accuracy : 0.42613636363636365, f1-score : 0.3090909090909091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45it [00:22,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9번 문제 점수 : accuracy : 0.45, f1-score : 0.26\n",
      "전체 문제 평균 accuracy : 0.6503173400673401, f1-score : 0.3143376623376624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 유사도 검사 -> Tokenizer 방식에서 띄어쓰기 단위로 2개씩 묶어서 window 방식으로 비교 + 키워드 변형\n",
    "threshold = 0.7\n",
    "total_acc, total_f1 = 0, 0\n",
    "word_concat_size = 2\n",
    "\n",
    "for i, key in enumerate(dataset):\n",
    "    acc, f1 = 0, 0\n",
    "    problem = dataset[key]\n",
    "    for j, (user_answer, ground_truth) in enumerate(tqdm(zip(problem.user_answers, problem.ground_truths))):\n",
    "        split_answer = user_answer.split(' ')\n",
    "        tokenized_answer = []\n",
    "        for k in range(len(split_answer) - word_concat_size):\n",
    "            tokenized_answer.append(' '.join(split_answer[k : k + word_concat_size]))\n",
    "        tokenized_answer_embedding = model.encode(tokenized_answer)\n",
    "        similarity_scores = cosine_similarity(problem.keywords_embedding, tokenized_answer_embedding)\n",
    "        predicts = [1 if score.max() > threshold else 0 for idx, score in enumerate(similarity_scores)]\n",
    "        acc += accuracy_score(ground_truth, predicts)\n",
    "        f1 += f1_score(ground_truth, predicts, zero_division=0)\n",
    "    print(f\"{i}번 문제 점수 : accuracy : {acc / len(problem.user_answers)}, f1-score : {f1 / len(problem.user_answers)}\")\n",
    "    total_acc += acc / len(problem.user_answers)\n",
    "    total_f1 += f1 / len(problem.user_answers)\n",
    "print(f\"전체 문제 평균 accuracy : {total_acc / len(dataset)}, f1-score : {total_f1 / len(dataset)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:02,  1.24it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [286]\u001B[0m, in \u001B[0;36m<cell line: 6>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     12\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m k \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(split_answer) \u001B[38;5;241m-\u001B[39m word_concat_size):\n\u001B[1;32m     13\u001B[0m     tokenized_answer\u001B[38;5;241m.\u001B[39mappend(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(split_answer[k : k \u001B[38;5;241m+\u001B[39m word_concat_size]))\n\u001B[0;32m---> 14\u001B[0m tokenized_answer_embedding \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencode\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtokenized_answer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     15\u001B[0m similarity_scores \u001B[38;5;241m=\u001B[39m cosine_similarity(problem\u001B[38;5;241m.\u001B[39mkeywords_embedding, tokenized_answer_embedding)\n\u001B[1;32m     16\u001B[0m predicts \u001B[38;5;241m=\u001B[39m [\u001B[38;5;241m1\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m score\u001B[38;5;241m.\u001B[39mmax() \u001B[38;5;241m>\u001B[39m threshold \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;241m0\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m idx, score \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(similarity_scores)]\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/ai-resesarch/lib/python3.8/site-packages/sentence_transformers/SentenceTransformer.py:165\u001B[0m, in \u001B[0;36mSentenceTransformer.encode\u001B[0;34m(self, sentences, batch_size, show_progress_bar, output_value, convert_to_numpy, convert_to_tensor, device, normalize_embeddings)\u001B[0m\n\u001B[1;32m    162\u001B[0m features \u001B[38;5;241m=\u001B[39m batch_to_device(features, device)\n\u001B[1;32m    164\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[0;32m--> 165\u001B[0m     out_features \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfeatures\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    167\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m output_value \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtoken_embeddings\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m    168\u001B[0m         embeddings \u001B[38;5;241m=\u001B[39m []\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/ai-resesarch/lib/python3.8/site-packages/torch/nn/modules/container.py:141\u001B[0m, in \u001B[0;36mSequential.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    139\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[1;32m    140\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[0;32m--> 141\u001B[0m         \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[43mmodule\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    142\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/ai-resesarch/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1106\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1107\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1108\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1109\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1110\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1111\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1112\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/ai-resesarch/lib/python3.8/site-packages/sentence_transformers/models/Transformer.py:66\u001B[0m, in \u001B[0;36mTransformer.forward\u001B[0;34m(self, features)\u001B[0m\n\u001B[1;32m     63\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtoken_type_ids\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01min\u001B[39;00m features:\n\u001B[1;32m     64\u001B[0m     trans_features[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtoken_type_ids\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m features[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtoken_type_ids\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[0;32m---> 66\u001B[0m output_states \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mauto_model\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mtrans_features\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m     67\u001B[0m output_tokens \u001B[38;5;241m=\u001B[39m output_states[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m     69\u001B[0m features\u001B[38;5;241m.\u001B[39mupdate({\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtoken_embeddings\u001B[39m\u001B[38;5;124m'\u001B[39m: output_tokens, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mattention_mask\u001B[39m\u001B[38;5;124m'\u001B[39m: features[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mattention_mask\u001B[39m\u001B[38;5;124m'\u001B[39m]})\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/ai-resesarch/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1106\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1107\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1108\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1109\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1110\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1111\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1112\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/ai-resesarch/lib/python3.8/site-packages/transformers/models/roberta/modeling_roberta.py:848\u001B[0m, in \u001B[0;36mRobertaModel.forward\u001B[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[1;32m    839\u001B[0m head_mask \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_head_mask(head_mask, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mnum_hidden_layers)\n\u001B[1;32m    841\u001B[0m embedding_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39membeddings(\n\u001B[1;32m    842\u001B[0m     input_ids\u001B[38;5;241m=\u001B[39minput_ids,\n\u001B[1;32m    843\u001B[0m     position_ids\u001B[38;5;241m=\u001B[39mposition_ids,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    846\u001B[0m     past_key_values_length\u001B[38;5;241m=\u001B[39mpast_key_values_length,\n\u001B[1;32m    847\u001B[0m )\n\u001B[0;32m--> 848\u001B[0m encoder_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencoder\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    849\u001B[0m \u001B[43m    \u001B[49m\u001B[43membedding_output\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    850\u001B[0m \u001B[43m    \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mextended_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    851\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhead_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    852\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    853\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoder_attention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoder_extended_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    854\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpast_key_values\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpast_key_values\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    855\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_cache\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_cache\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    856\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    857\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    858\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    859\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    860\u001B[0m sequence_output \u001B[38;5;241m=\u001B[39m encoder_outputs[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m    861\u001B[0m pooled_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpooler(sequence_output) \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpooler \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/ai-resesarch/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1106\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1107\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1108\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1109\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1110\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1111\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1112\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/ai-resesarch/lib/python3.8/site-packages/transformers/models/roberta/modeling_roberta.py:524\u001B[0m, in \u001B[0;36mRobertaEncoder.forward\u001B[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[1;32m    515\u001B[0m     layer_outputs \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mutils\u001B[38;5;241m.\u001B[39mcheckpoint\u001B[38;5;241m.\u001B[39mcheckpoint(\n\u001B[1;32m    516\u001B[0m         create_custom_forward(layer_module),\n\u001B[1;32m    517\u001B[0m         hidden_states,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    521\u001B[0m         encoder_attention_mask,\n\u001B[1;32m    522\u001B[0m     )\n\u001B[1;32m    523\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 524\u001B[0m     layer_outputs \u001B[38;5;241m=\u001B[39m \u001B[43mlayer_module\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    525\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    526\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    527\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlayer_head_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    528\u001B[0m \u001B[43m        \u001B[49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    529\u001B[0m \u001B[43m        \u001B[49m\u001B[43mencoder_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    530\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpast_key_value\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    531\u001B[0m \u001B[43m        \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    532\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    534\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m layer_outputs[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m    535\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m use_cache:\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/ai-resesarch/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1106\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1107\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1108\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1109\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1110\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1111\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1112\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/ai-resesarch/lib/python3.8/site-packages/transformers/models/roberta/modeling_roberta.py:451\u001B[0m, in \u001B[0;36mRobertaLayer.forward\u001B[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001B[0m\n\u001B[1;32m    448\u001B[0m     cross_attn_present_key_value \u001B[38;5;241m=\u001B[39m cross_attention_outputs[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\n\u001B[1;32m    449\u001B[0m     present_key_value \u001B[38;5;241m=\u001B[39m present_key_value \u001B[38;5;241m+\u001B[39m cross_attn_present_key_value\n\u001B[0;32m--> 451\u001B[0m layer_output \u001B[38;5;241m=\u001B[39m \u001B[43mapply_chunking_to_forward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    452\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfeed_forward_chunk\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mchunk_size_feed_forward\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mseq_len_dim\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattention_output\u001B[49m\n\u001B[1;32m    453\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    454\u001B[0m outputs \u001B[38;5;241m=\u001B[39m (layer_output,) \u001B[38;5;241m+\u001B[39m outputs\n\u001B[1;32m    456\u001B[0m \u001B[38;5;66;03m# if decoder, return the attn key/values as the last output\u001B[39;00m\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/ai-resesarch/lib/python3.8/site-packages/transformers/pytorch_utils.py:241\u001B[0m, in \u001B[0;36mapply_chunking_to_forward\u001B[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001B[0m\n\u001B[1;32m    238\u001B[0m     \u001B[38;5;66;03m# concatenate output at same dimension\u001B[39;00m\n\u001B[1;32m    239\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mcat(output_chunks, dim\u001B[38;5;241m=\u001B[39mchunk_dim)\n\u001B[0;32m--> 241\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43minput_tensors\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/ai-resesarch/lib/python3.8/site-packages/transformers/models/roberta/modeling_roberta.py:464\u001B[0m, in \u001B[0;36mRobertaLayer.feed_forward_chunk\u001B[0;34m(self, attention_output)\u001B[0m\n\u001B[1;32m    462\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfeed_forward_chunk\u001B[39m(\u001B[38;5;28mself\u001B[39m, attention_output):\n\u001B[1;32m    463\u001B[0m     intermediate_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mintermediate(attention_output)\n\u001B[0;32m--> 464\u001B[0m     layer_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moutput\u001B[49m\u001B[43m(\u001B[49m\u001B[43mintermediate_output\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattention_output\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    465\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m layer_output\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/ai-resesarch/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1106\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1107\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1108\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1109\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1110\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1111\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1112\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/ai-resesarch/lib/python3.8/site-packages/transformers/models/roberta/modeling_roberta.py:375\u001B[0m, in \u001B[0;36mRobertaOutput.forward\u001B[0;34m(self, hidden_states, input_tensor)\u001B[0m\n\u001B[1;32m    374\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, hidden_states: torch\u001B[38;5;241m.\u001B[39mTensor, input_tensor: torch\u001B[38;5;241m.\u001B[39mTensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m torch\u001B[38;5;241m.\u001B[39mTensor:\n\u001B[0;32m--> 375\u001B[0m     hidden_states \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdense\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    376\u001B[0m     hidden_states \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdropout(hidden_states)\n\u001B[1;32m    377\u001B[0m     hidden_states \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mLayerNorm(hidden_states \u001B[38;5;241m+\u001B[39m input_tensor)\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/ai-resesarch/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1106\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1107\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1108\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1109\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1110\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1111\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1112\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/ai-resesarch/lib/python3.8/site-packages/torch/nn/modules/linear.py:103\u001B[0m, in \u001B[0;36mLinear.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    102\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m--> 103\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlinear\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# 유사도 검사 -> Tokenizer 방식에서 띄어쓰기 단위로 2개씩 묶어서 window 방식으로 비교 + 키워드 변형, threshold 0.5로 낮춤\n",
    "threshold = 0.5\n",
    "total_acc, total_f1 = 0, 0\n",
    "word_concat_size = 2\n",
    "\n",
    "for i, key in enumerate(dataset):\n",
    "    acc, f1 = 0, 0\n",
    "    problem = dataset[key]\n",
    "    for j, (user_answer, ground_truth) in enumerate(tqdm(zip(problem.user_answers, problem.ground_truths))):\n",
    "        split_answer = user_answer.split(' ')\n",
    "        tokenized_answer = []\n",
    "        for k in range(len(split_answer) - word_concat_size):\n",
    "            tokenized_answer.append(' '.join(split_answer[k : k + word_concat_size]))\n",
    "        tokenized_answer_embedding = model.encode(tokenized_answer)\n",
    "        similarity_scores = cosine_similarity(problem.keywords_embedding, tokenized_answer_embedding)\n",
    "        predicts = [1 if score.max() > threshold else 0 for idx, score in enumerate(similarity_scores)]\n",
    "        acc += accuracy_score(ground_truth, predicts)\n",
    "        f1 += f1_score(ground_truth, predicts, zero_division=0)\n",
    "    print(f\"{i}번 문제 점수 : accuracy : {acc / len(problem.user_answers)}, f1-score : {f1 / len(problem.user_answers)}\")\n",
    "    total_acc += acc / len(problem.user_answers)\n",
    "    total_f1 += f1 / len(problem.user_answers)\n",
    "print(f\"전체 문제 평균 accuracy : {total_acc / len(dataset)}, f1-score : {total_f1 / len(dataset)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45it [00:28,  1.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0번 문제 점수 : accuracy : 0.9055555555555556, f1-score : 0.8817989417989417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45it [00:27,  1.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1번 문제 점수 : accuracy : 0.8148148148148151, f1-score : 0.731851851851852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45it [00:34,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2번 문제 점수 : accuracy : 0.8592592592592594, f1-score : 0.8096296296296297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45it [00:39,  1.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3번 문제 점수 : accuracy : 0.8277777777777777, f1-score : 0.8772486772486771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45it [00:33,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4번 문제 점수 : accuracy : 0.8333333333333334, f1-score : 0.6780952380952382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45it [00:20,  2.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5번 문제 점수 : accuracy : 0.706666666666667, f1-score : 0.45391534391534394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45it [00:26,  1.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6번 문제 점수 : accuracy : 0.8266666666666668, f1-score : 0.6895238095238098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45it [00:16,  2.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7번 문제 점수 : accuracy : 0.8277777777777777, f1-score : 0.7778835978835977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "44it [00:31,  1.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8번 문제 점수 : accuracy : 0.8011363636363636, f1-score : 0.8121212121212121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45it [00:28,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9번 문제 점수 : accuracy : 0.8055555555555556, f1-score : 0.7843386243386246\n",
      "전체 문제 평균 accuracy : 0.8208543771043771, f1-score : 0.7496406926406927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 유사도 검사 -> Tokenizer 방식에서 띄어쓰기 단위로 2개씩 묶어서 window 방식으로 비교 + 키워드 변형 -> 윈도우 사이즈 3으로 늘림, threshold 0.35로 낮춤\n",
    "threshold = 0.35\n",
    "total_acc, total_f1 = 0, 0\n",
    "word_concat_size = 3\n",
    "\n",
    "for i, key in enumerate(dataset):\n",
    "    acc, f1 = 0, 0\n",
    "    problem = dataset[key]\n",
    "    for j, (user_answer, ground_truth) in enumerate(tqdm(zip(problem.user_answers, problem.ground_truths))):\n",
    "        split_answer = user_answer.split(' ')\n",
    "        tokenized_answer = []\n",
    "        for k in range(len(split_answer) - word_concat_size + 1):\n",
    "            tokenized_answer.append(' '.join(split_answer[k : k + word_concat_size]))\n",
    "        if len(split_answer) < word_concat_size:\n",
    "            tokenized_answer.append(' '.join(split_answer))\n",
    "        tokenized_answer_embedding = model.encode(tokenized_answer)\n",
    "        similarity_scores = cosine_similarity(problem.keywords_embedding, tokenized_answer_embedding)\n",
    "        predicts = [1 if score.max() > threshold else 0 for idx, score in enumerate(similarity_scores)]\n",
    "\n",
    "        acc += accuracy_score(ground_truth, predicts)\n",
    "        f1 += f1_score(ground_truth, predicts, zero_division=1)\n",
    "    print(f\"{i}번 문제 점수 : accuracy : {acc / len(problem.user_answers)}, f1-score : {f1 / len(problem.user_answers)}\")\n",
    "    total_acc += acc / len(problem.user_answers)\n",
    "    total_f1 += f1 / len(problem.user_answers)\n",
    "print(f\"전체 문제 평균 accuracy : {total_acc / len(dataset)}, f1-score : {total_f1 / len(dataset)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "### 왜 5번문제만 f1 score가 저 모양일까?\n",
    "---"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[데이터베이스 1] Primary key가 무엇인지 설명해주세요.\n",
      "정답 키워드 : ['최소성', '대표성', '유일성', '불변성', '식별자']\n",
      "{'식별자': '22%', '유일성': '31%', '최소성': '8%', '대표성': '8%', '불변성': '2%'}\n"
     ]
    }
   ],
   "source": [
    "problem = dataset['recio3s0A77i0kkEn']\n",
    "\n",
    "print(problem.subject)\n",
    "print(f\"정답 키워드 : {problem.keywords}\")\n",
    "keyword_count = {}\n",
    "for answer, keywords in zip(problem.user_answers, problem.user_correct_keywords):\n",
    "    for keyword in keywords:\n",
    "        if keyword not in keyword_count:\n",
    "            keyword_count[keyword] = 1\n",
    "        else:\n",
    "            keyword_count[keyword] += 1\n",
    "for keyword in keyword_count:\n",
    "    keyword_count[keyword] = f\"{int(keyword_count[keyword] / len(problem.user_answers) * 100)}%\"\n",
    "print(keyword_count)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "#### 자세히 보면 키워드가 너무 어려웠는지 정답률이 엉망이다.\n",
    "#### 실제 정답에 1이 없다면 f1 score는 무조건 0이다.\n",
    "#### 이는 키워드가 적절치 않았는지를 고려해봐야 할 듯 하다.\n",
    "---"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "### 이제 실제로 모델이 어떻게 예측하고 있는지 눈으로 확인해보자!!\n",
    "---"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword          : 저장위치\n",
      "detected keyword : 저장된다. 세션은 접속중인\n",
      "keyword          : 속도\n",
      "detected keyword : 더 빠르다. 왜냐하면\n",
      "실제 정답 : ['저장위치', '속도']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:01,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword          : 보안\n",
      "detected keyword : 비해 보안도 높은\n",
      "keyword          : 저장위치\n",
      "detected keyword : 저장되고, 서버자원을 사용하기\n",
      "keyword          : 속도\n",
      "detected keyword : 속도를 높일 수\n",
      "실제 정답 : ['보안', '저장위치', '속도']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:02,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword          : 보안\n",
      "detected keyword : 사용합니다. 보안 면에서\n",
      "keyword          : 저장위치\n",
      "detected keyword : 정보가 저장되는 위치입니다.\n",
      "keyword          : 속도\n",
      "detected keyword : 더 빠릅니다. 그\n",
      "실제 정답 : ['보안', '저장위치', '속도']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:02,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword          : 보안\n",
      "detected keyword : 처리하기 때문에 보안성이\n",
      "keyword          : 저장위치\n",
      "detected keyword : 로컬에 저장되기 때문에\n",
      "실제 정답 : ['보안', '저장위치']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:03,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword          : 만료\n",
      "detected keyword : 만료시간을 정할 수\n",
      "keyword          : 저장위치\n",
      "detected keyword : 저장되기 때문에 브라우저를\n",
      "실제 정답 : ['Lifecycle']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:03,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword          : 속도\n",
      "detected keyword : 느린 속도를 가집니다.\n",
      "실제 정답 : ['속도']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:04,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword          : 저장위치\n",
      "detected keyword : 저장합니다. 저장할 때\n",
      "실제 정답 : ['저장위치']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [00:04,  1.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword          : 저장위치\n",
      "detected keyword : 저장되고 클라이언트의 메모리를\n",
      "실제 정답 : ['저장위치']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [00:06,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword          : 만료\n",
      "detected keyword : 종료시 만료) 반면에\n",
      "keyword          : 저장위치\n",
      "detected keyword : 쿠키는 저장할 때\n",
      "실제 정답 : ['Lifecycle']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:08,  1.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword          : 저장위치\n",
      "detected keyword : 저장할 지 적절한\n",
      "실제 정답 : ['보안', '저장위치']\n",
      "0번 문제 점수 : accuracy : 0.20555555555555555, f1-score : 0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  2.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword          : 동일한 요청\n",
      "detected keyword : 여러 번 적용하더라도\n",
      "실제 정답 : ['동일한 요청']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:00,  2.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword          : 동일한 요청\n",
      "detected keyword : 경우 같은 행위를\n",
      "실제 정답 : ['동일한 요청']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:01,  2.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword          : 동일한 요청\n",
      "detected keyword : 한 요청에 대한\n",
      "keyword          : stateless\n",
      "detected keyword : 상태는 항상 같습니다.\n",
      "실제 정답 : ['stateless']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:01,  2.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword          : 동일한 요청\n",
      "detected keyword : 동일한 요청을 한번\n",
      "실제 정답 : ['동일한 요청', 'stateless']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:02,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword          : 동일한 요청\n",
      "detected keyword : 이다. 같은 요청을\n",
      "keyword          : stateless\n",
      "detected keyword : 상태가 항상 같은\n",
      "실제 정답 : ['동일한 요청', 'stateless']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:04,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword          : POST\n",
      "detected keyword : POST, PUT, PATCH,\n",
      "실제 정답 : ['POST']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:06,  1.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword          : 동일한 요청\n",
      "detected keyword : 여러번 요청을 보내더라도\n",
      "keyword          : stateless\n",
      "detected keyword : 상태가 변하지 않는\n",
      "실제 정답 : ['동일한 요청', 'stateless']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [00:07,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword          : POST\n",
      "detected keyword : 멱등성을 가지며 POST\n",
      "keyword          : 동일한 요청\n",
      "detected keyword : 동일한 요청을 한\n",
      "실제 정답 : ['POST', '동일한 요청', 'stateless']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [00:08,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword          : 동일한 요청\n",
      "detected keyword : 동일한 요청을 한\n",
      "keyword          : stateless\n",
      "detected keyword : 상태도 동일하게 남는\n",
      "실제 정답 : ['동일한 요청', 'stateless']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:09,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword          : POST\n",
      "detected keyword : 멱등하다라고고 한다. PUT,\n",
      "keyword          : 동일한 요청\n",
      "detected keyword : 요청을 여러번 하더라도\n",
      "실제 정답 : ['POST', '동일한 요청']\n",
      "1번 문제 점수 : accuracy : 0.2, f1-score : 0.20296296296296296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:01,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword          : 저장 순서\n",
      "detected keyword : 순차적으로 저장한다. 또한\n",
      "실제 정답 : ['저장 순서']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:02,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword          : 랜덤 액세스\n",
      "detected keyword : random access가 가능하다.\n",
      "keyword          : 저장 순서\n",
      "detected keyword : 저장 순서와 물리적\n",
      "실제 정답 : ['랜덤 액세스', '저장 순서']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:03,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword          : 저장 순서\n",
      "detected keyword : 순차적으로 데이터를 저장한다.\n",
      "실제 정답 : ['저장 순서']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:03,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword          : 랜덤 액세스\n",
      "detected keyword : 무작위 접근(random access)가\n",
      "keyword          : 시간 복잡도\n",
      "detected keyword : 빠르다. 순차 접근(sequential\n",
      "keyword          : 저장 순서\n",
      "detected keyword : 순차적으로 저장된다. 따라서\n",
      "실제 정답 : ['랜덤 액세스', '저장 순서']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:04,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword          : 저장 순서\n",
      "detected keyword : 메모리 공간으로 이루어져있다.\n",
      "실제 정답 : []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:05,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword          : 저장 순서\n",
      "detected keyword : 저장 순서와 물리적\n",
      "실제 정답 : ['저장 순서']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:06,  1.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword          : 랜덤 액세스\n",
      "detected keyword : random access 에\n",
      "keyword          : 시간 복잡도\n",
      "detected keyword : 강하다. 시간 복잡도가\n",
      "keyword          : 저장 순서\n",
      "detected keyword : 메모리 공간에 순차적으로\n",
      "실제 정답 : ['랜덤 액세스', '시간 복잡도']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [00:08,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword          : 저장 순서\n",
      "detected keyword : 순서대로 데이터를 저장합니다.\n",
      "실제 정답 : ['저장 순서']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [00:09,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword          : 저장 순서\n",
      "detected keyword : 저장할 수 있어\n",
      "실제 정답 : ['시간 복잡도', '저장 순서']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:10,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword          : 랜덤 액세스\n",
      "detected keyword : 접근이 가능하다.(Random Access\n",
      "keyword          : 저장 순서\n",
      "detected keyword : 저장 순서가 일치한다.\n",
      "실제 정답 : ['랜덤 액세스', '시간 복잡도', '저장 순서']\n",
      "2번 문제 점수 : accuracy : 0.1851851851851852, f1-score : 0.17925925925925926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:01,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword          : 일관성\n",
      "detected keyword : 일관성, 독립성. 지속성.\n",
      "keyword          : 독립성\n",
      "detected keyword : 한다를 뜻한다. 독립성은\n",
      "keyword          : 지속성\n",
      "detected keyword : 의미한다. 지속성은 트랜잭션이\n",
      "keyword          : 원자성\n",
      "detected keyword : 원자성은 트랜잭션이 DB에\n",
      "실제 정답 : ['일관성', '독립성', '지속성', '원자성']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:02,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword          : 일관성\n",
      "detected keyword : 일관성이 있어야 한다는\n",
      "keyword          : 독립성\n",
      "detected keyword : 있어야 한다는 것.독립성\n",
      "keyword          : 지속성\n",
      "detected keyword : 들수 없다는 점.지속성\n",
      "keyword          : 원자성\n",
      "detected keyword : 원자성은 트랜잭션이 데이터베이스에\n",
      "실제 정답 : ['일관성', '독립성', '지속성', '원자성']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:04,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword          : 일관성\n",
      "detected keyword : 한다. 일관성 :\n",
      "keyword          : 독립성\n",
      "detected keyword : 한다. 독립성 :\n",
      "keyword          : 지속성\n",
      "detected keyword : 영속성 : 트랜잭션이\n",
      "keyword          : 원자성\n",
      "detected keyword : 말합니다. 원자성 :\n",
      "실제 정답 : ['일관성', '독립성', '지속성', '원자성']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:05,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword          : 일관성\n",
      "detected keyword : 일관성이 있어야 한다는\n",
      "keyword          : 독립성\n",
      "detected keyword : 한다는 것. 독립성은\n",
      "keyword          : 지속성\n",
      "detected keyword : 없다는 점. 지속성은\n",
      "keyword          : 원자성\n",
      "detected keyword : 원자성은 트랜잭션이 데이터베이스에\n",
      "실제 정답 : ['일관성', '독립성', '지속성', '원자성']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:07,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword          : 일관성\n",
      "detected keyword : 일관성 : 일관성\n",
      "keyword          : 독립성\n",
      "detected keyword : 유지. 독립성 :\n",
      "keyword          : 지속성\n",
      "detected keyword : 것. 지속성 :\n",
      "keyword          : 원자성\n",
      "detected keyword : 약어. 원자성 :\n",
      "실제 정답 : ['일관성', '독립성', '지속성', '원자성']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:08,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword          : 일관성\n",
      "detected keyword : 데이터의 신뢰성과 일관성을\n",
      "keyword          : 지속성\n",
      "detected keyword : 신뢰성과 일관성을 보장합니다.\n",
      "실제 정답 : []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:09,  1.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword          : 일관성\n",
      "detected keyword : 일관성 있는 상태를\n",
      "keyword          : 지속성\n",
      "detected keyword : 보장하는 것. 지속성은\n",
      "keyword          : 원자성\n",
      "detected keyword : 원자성은 트랜잭션을 구성하는\n",
      "실제 정답 : ['일관성', '독립성', '지속성', '원자성']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [00:10,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword          : 일관성\n",
      "detected keyword : Consistency(일관성), Isolation(독립성), Durability(영속성)의\n",
      "keyword          : 독립성\n",
      "detected keyword : Isolation(독립성), Durability(영속성)의 앞글자를\n",
      "keyword          : 지속성\n",
      "detected keyword : Durability(영속성)의 앞글자를 따\n",
      "keyword          : 원자성\n",
      "detected keyword : 로 표현한다. Atomicity(원자성),\n",
      "실제 정답 : ['일관성', '독립성', '지속성', '원자성']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [00:11,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword          : 일관성\n",
      "detected keyword : / Consistency[일관성] /\n",
      "keyword          : 지속성\n",
      "detected keyword : / Durability[지속성])로 표현된다.\n",
      "keyword          : 원자성\n",
      "detected keyword : 성질으로, ACID (Atomicity[원자성]\n",
      "실제 정답 : ['일관성', '독립성', '지속성', '원자성']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:12,  1.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword          : 일관성\n",
      "detected keyword : 일관성있는 데이터베이스 상태로\n",
      "keyword          : 독립성\n",
      "detected keyword : 상태로 유지해야 함.독립성\n",
      "keyword          : 지속성\n",
      "detected keyword : 함.지속성 -성공적으로 수행된\n",
      "keyword          : 원자성\n",
      "detected keyword : 구분됩니다.원자성 - 데이터베이스에\n",
      "실제 정답 : ['일관성', '독립성', '지속성', '원자성']\n",
      "3번 문제 점수 : accuracy : 0.2, f1-score : 0.19365079365079363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:01,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword          : 상호 배제\n",
      "detected keyword : 먼저 상호배제는 한\n",
      "keyword          : 점유 대기\n",
      "detected keyword : 기다려야 합니다. 점유대기는\n",
      "keyword          : 순환 대기\n",
      "detected keyword : 조건입니다. 순환대기는 이미\n",
      "keyword          : 비선점\n",
      "detected keyword : 합니다. 비선점은 이미\n",
      "실제 정답 : ['상호 배제', '점유 대기', '순환 대기', '비선점']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:02,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword          : 상호 배제\n",
      "detected keyword : 첫번째로 상호배제가 있다.\n",
      "keyword          : 점유 대기\n",
      "detected keyword : 조건은 점유대기 조건과\n",
      "keyword          : 순환 대기\n",
      "detected keyword : 이 중 순환대기\n",
      "keyword          : 비선점\n",
      "detected keyword : 비선점 조건을 만족해야\n",
      "실제 정답 : ['상호 배제', '점유 대기', '순환 대기', '비선점']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:05,  1.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword          : 상호 배제\n",
      "detected keyword : 발생하지 않는다.상호 배제(Mutual\n",
      "keyword          : 점유 대기\n",
      "detected keyword : 뜻함.점유와 대기(Hold and\n",
      "keyword          : 순환 대기\n",
      "detected keyword : 않는다)환형 대기(Circular wait)는\n",
      "keyword          : 비선점\n",
      "detected keyword : 뜻함.비선점(No preemption)은프로세스가 태스크를\n",
      "실제 정답 : ['상호 배제', '점유 대기', '순환 대기', '비선점']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:07,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword          : 상호 배제\n",
      "detected keyword : 때 발생한다.상호 배제(Mutual\n",
      "keyword          : 점유 대기\n",
      "detected keyword : 있어야 한다.점유 대기\n",
      "keyword          : 순환 대기\n",
      "detected keyword : 한다.순환 대기 (Circular\n",
      "keyword          : 비선점\n",
      "detected keyword : 프로세스가 존재해야 한다.비선점\n",
      "실제 정답 : ['상호 배제', '점유 대기', '순환 대기', '비선점']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:08,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword          : 상호 배제\n",
      "detected keyword : Exclusion(상호 배타적)하나의 프로세스가\n",
      "keyword          : 점유 대기\n",
      "detected keyword : 기다릴 때 보유\n",
      "keyword          : 순환 대기\n",
      "detected keyword : 기다리는 프로세스간에 사이클이\n",
      "keyword          : 비선점\n",
      "detected keyword : 형성되어야 함프로세스 P0,\n",
      "실제 정답 : ['상호 배제', '점유 대기', '순환 대기', '비선점']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:10,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword          : 상호 배제\n",
      "detected keyword : 1. 상호 배제(Mutual\n",
      "keyword          : 점유 대기\n",
      "detected keyword : 있음2. 점유 대기(Hold\n",
      "keyword          : 순환 대기\n",
      "detected keyword : 순환 대기(Circular Wait)프로세스의\n",
      "keyword          : 비선점\n",
      "detected keyword : 자원을 기다림3. 비선점(No\n",
      "실제 정답 : ['상호 배제', '점유 대기', '순환 대기', '비선점']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:10,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "실제 정답 : []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [00:11,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword          : 상호 배제\n",
      "detected keyword : 상호 배제, 점유\n",
      "keyword          : 점유 대기\n",
      "detected keyword : 배제, 점유 대기,\n",
      "keyword          : 순환 대기\n",
      "detected keyword : 대기, 비선점, 순환\n",
      "keyword          : 비선점\n",
      "detected keyword : 비선점, 순환 대기\n",
      "실제 정답 : ['상호 배제', '점유 대기', '순환 대기', '비선점']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [00:13,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword          : 점유 대기\n",
      "detected keyword : 점유하기 위해 대기하는\n",
      "keyword          : 순환 대기\n",
      "detected keyword : 순환 형태로 자원을\n",
      "실제 정답 : []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:15,  1.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword          : 상호 배제\n",
      "detected keyword : 해결된다.상호 배제 Mutal\n",
      "keyword          : 점유 대기\n",
      "detected keyword : 수 없다.점유 대기\n",
      "keyword          : 순환 대기\n",
      "detected keyword : 있어야 한다.순환 대기\n",
      "keyword          : 비선점\n",
      "detected keyword : 수 없다.비선점 No\n",
      "실제 정답 : ['상호 배제', '점유 대기', '순환 대기', '비선점']\n",
      "4번 문제 점수 : accuracy : 0.2111111111111111, f1-score : 0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword          : 대표성\n",
      "detected keyword : 식별자로 이용하기에 가장\n",
      "keyword          : 식별자\n",
      "detected keyword : 식별자로 이용하기에 가장\n",
      "실제 정답 : ['식별자']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:01,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword          : 유일성\n",
      "detected keyword : 유일하게 구별할 수\n",
      "keyword          : 불변성\n",
      "detected keyword : 속성에는 동일한 값이\n",
      "keyword          : 식별자\n",
      "detected keyword : 구별할 수 있는\n",
      "실제 정답 : ['유일성', '식별자']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:02,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword          : 최소성\n",
      "detected keyword : 최소성을 가지며 튜플을\n",
      "keyword          : 대표성\n",
      "detected keyword : 성질을 갖는다. 즉,\n",
      "keyword          : 유일성\n",
      "detected keyword : 갖는다. 즉, 유일성과\n",
      "keyword          : 불변성\n",
      "detected keyword : 즉, 유일성과 최소성을\n",
      "keyword          : 식별자\n",
      "detected keyword : 식별하기 위해 반드시\n",
      "실제 정답 : ['최소성', '유일성', '식별자']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:02,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword          : 대표성\n",
      "detected keyword : 대표하는 키다. 때문에\n",
      "실제 정답 : ['대표성']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:03,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword          : 대표성\n",
      "detected keyword : 있는 속성을 가지며\n",
      "keyword          : 유일성\n",
      "detected keyword : 유일하게 구별할 수\n",
      "keyword          : 식별자\n",
      "detected keyword : 구별할 수 있는\n",
      "실제 정답 : ['유일성', '식별자']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:04,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword          : 유일성\n",
      "detected keyword : 유일하게 구별할 수\n",
      "keyword          : 불변성\n",
      "detected keyword : 있는 속성이다. 기본키는\n",
      "keyword          : 식별자\n",
      "detected keyword : 구별할 수 있는\n",
      "실제 정답 : ['유일성']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:04,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "실제 정답 : []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [00:04,  2.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword          : 대표성\n",
      "detected keyword : 식별자로 선택한 하나의\n",
      "keyword          : 유일성\n",
      "detected keyword : 선택한 하나의 키\n",
      "keyword          : 식별자\n",
      "detected keyword : 식별자로 선택한 하나의\n",
      "실제 정답 : []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [00:05,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword          : 대표성\n",
      "detected keyword : 선정하여 대표로 삼는\n",
      "keyword          : 유일성\n",
      "detected keyword : 하나뿐이라면 그 후보키를\n",
      "keyword          : 식별자\n",
      "detected keyword : 특성을 반영하여 하나를\n",
      "실제 정답 : []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:05,  1.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword          : 최소성\n",
      "detected keyword : 키로 최소성과 유일성을\n",
      "keyword          : 유일성\n",
      "detected keyword : 유일성을 만족하는 속성이다.\n",
      "keyword          : 불변성\n",
      "detected keyword : 키로 최소성과 유일성을\n",
      "실제 정답 : ['최소성', '유일성']\n",
      "5번 문제 점수 : accuracy : 0.16, f1-score : 0.14037037037037037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  3.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword          : 작업단위\n",
      "detected keyword : 작업의 단위이고 스레드는\n",
      "keyword          : 스택\n",
      "detected keyword : 작업의 단위이고 스레드는\n",
      "실제 정답 : ['작업단위']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:00,  3.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword          : 작업단위\n",
      "detected keyword : 작업 단위를 뜻하며\n",
      "keyword          : 스택\n",
      "detected keyword : 스레드가 생겨날 수\n",
      "실제 정답 : ['작업단위']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:01,  2.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword          : 작업단위\n",
      "detected keyword : 작업의 단위이고 스레드는\n",
      "keyword          : 스택\n",
      "detected keyword : 작업의 단위이고 스레드는\n",
      "실제 정답 : ['작업단위']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:01,  1.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword          : 작업단위\n",
      "detected keyword : 작업의 단위이며 프로세스를\n",
      "keyword          : 스택\n",
      "detected keyword : 스레드에 스택만 따로\n",
      "keyword          : 메모리\n",
      "detected keyword : 할당할 때 메모리의\n",
      "keyword          : 영역 공유\n",
      "detected keyword : 공유하기 때문에 각\n",
      "실제 정답 : ['작업단위', 'Stack', '메모리', '영역 공유']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:02,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword          : 작업단위\n",
      "detected keyword : 작업의 단위이며 프로세스를\n",
      "keyword          : 스택\n",
      "detected keyword : 스택, 힙, 코드,\n",
      "keyword          : 메모리\n",
      "detected keyword : 할당할 때 메모리의\n",
      "keyword          : 영역 공유\n",
      "detected keyword : 공유하기 때문에 스택영역만\n",
      "실제 정답 : ['작업단위', 'Stack', '메모리', '영역 공유']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:04,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword          : 작업단위\n",
      "detected keyword : 일을 처리하는 일련의\n",
      "keyword          : 스택\n",
      "detected keyword : 그리고 스레드는 한\n",
      "keyword          : 영역 공유\n",
      "detected keyword : 하나에 자원을 공유하면서\n",
      "실제 정답 : ['영역 공유']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:05,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword          : 작업단위\n",
      "detected keyword : 단위로 실행되며 모든\n",
      "keyword          : 스택\n",
      "detected keyword : 하지만 스레드는 한\n",
      "keyword          : 영역 공유\n",
      "detected keyword : 공유합니다. 기본적으로 하나의\n",
      "실제 정답 : ['영역 공유']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [00:05,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword          : 작업단위\n",
      "detected keyword : 작업의 단위이고 스레드는\n",
      "keyword          : 스택\n",
      "detected keyword : 작업의 단위이고 스레드는\n",
      "keyword          : 영역 공유\n",
      "detected keyword : 자원들을 대부분 공유한다.\n",
      "실제 정답 : ['작업단위', '영역 공유']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [00:05,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword          : 작업단위\n",
      "detected keyword : 작업 단위로 분류합니다\n",
      "keyword          : 스택\n",
      "detected keyword : 그리고 스레드란 한\n",
      "keyword          : 메모리\n",
      "detected keyword : 메모리에 올라와 실행되고\n",
      "실제 정답 : ['작업단위', '메모리']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:06,  1.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword          : 스택\n",
      "detected keyword : 있는 프로그램이고 스레드는\n",
      "실제 정답 : []\n",
      "6번 문제 점수 : accuracy : 0.17777777777777776, f1-score : 0.14666666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:01,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword          : 수정 빈도\n",
      "detected keyword : 호출 빈도는 자주\n",
      "keyword          : 조회 빈도\n",
      "detected keyword : 호출 빈도는 자주\n",
      "keyword          : 선택도\n",
      "detected keyword : 좋습니다. 가장 최선은\n",
      "실제 정답 : ['조회 빈도']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:02,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword          : 카디널리티\n",
      "detected keyword : 카디널리티가 높으면 인덱스\n",
      "keyword          : 수정 빈도\n",
      "detected keyword : 수정 빈도가 낮으면\n",
      "keyword          : 조회 빈도\n",
      "detected keyword : 빈도가 낮으면 인덱스\n",
      "keyword          : 선택도\n",
      "detected keyword : 좋은 컬럼이다. 선택도가\n",
      "실제 정답 : ['카디널리티', '수정 빈도', '조회 빈도', '선택도']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:03,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword          : 카디널리티\n",
      "detected keyword : 대한 정보를 기수성(Cardinality)라고\n",
      "keyword          : 수정 빈도\n",
      "detected keyword : 낮고, 중복되는 횟수가\n",
      "keyword          : 조회 빈도\n",
      "detected keyword : 경우 조회 성능이\n",
      "keyword          : 선택도\n",
      "detected keyword : 선택도 또한 같이\n",
      "실제 정답 : ['카디널리티', '선택도']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:04,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword          : 카디널리티\n",
      "detected keyword : Cardinality라고 하며 한\n",
      "keyword          : 조회 빈도\n",
      "detected keyword : 자주 사용되는 지를\n",
      "실제 정답 : ['카디널리티']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:06,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword          : 수정 빈도\n",
      "detected keyword : 호출 빈도는 자주\n",
      "keyword          : 조회 빈도\n",
      "detected keyword : 호출 빈도는 자주\n",
      "keyword          : 선택도\n",
      "detected keyword : 좋다. 가장 최선은\n",
      "실제 정답 : ['조회 빈도']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:07,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword          : 조회 빈도\n",
      "detected keyword : 자주 사용되는 컬럼\n",
      "실제 정답 : ['조회 빈도']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:08,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword          : 조회 빈도\n",
      "detected keyword : 자주 발생하지 않는\n",
      "실제 정답 : ['수정 빈도']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [00:09,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword          : 카디널리티\n",
      "detected keyword : 한다는 점입니다.카디널리티(Cardinality)란 해당\n",
      "keyword          : 선택도\n",
      "detected keyword : 하나를 선택하기 때문에\n",
      "실제 정답 : ['카디널리티']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [00:09,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword          : 카디널리티\n",
      "detected keyword : 위주로 카디널리티가 높은\n",
      "keyword          : 조회 빈도\n",
      "detected keyword : 조회시 자주 사용하는\n",
      "실제 정답 : ['카디널리티', '조회 빈도']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:10,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword          : 조회 빈도\n",
      "detected keyword : 자주 조회되는 컬럼을\n",
      "실제 정답 : ['조회 빈도']\n",
      "7번 문제 점수 : accuracy : 0.16666666666666666, f1-score : 0.15555555555555556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:01,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword          : 삽입\n",
      "detected keyword : 넣고 뺄 수\n",
      "keyword          : LIFO\n",
      "detected keyword : LIFO(Last In First\n",
      "실제 정답 : ['삭제', '삽입', 'LIFO']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:01,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword          : LIFO\n",
      "detected keyword : LIFO) 의 형태를\n",
      "실제 정답 : ['삭제', 'LIFO']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:02,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword          : 삭제\n",
      "detected keyword : 자료가 삭제 됩니다.\n",
      "keyword          : LIFO\n",
      "detected keyword : LIFO 구조로, 가장\n",
      "실제 정답 : ['삭제', 'LIFO']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:03,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword          : 삭제\n",
      "detected keyword : 삭제가 이루어지기 때문에\n",
      "keyword          : 삽입\n",
      "detected keyword : 때문에 나중에 삽입된\n",
      "keyword          : LIFO\n",
      "detected keyword : 먼저 삭제되는 후입선출(LIFO,\n",
      "실제 정답 : ['삭제', '삽입', 'LIFO']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:05,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword          : 삭제\n",
      "detected keyword : 자료를 삭제할 때도\n",
      "keyword          : 삽입\n",
      "detected keyword : 통해 삽입하는 연산을\n",
      "keyword          : LIFO\n",
      "detected keyword : 이러한 스택의 구조를후입선출(LIFO,\n",
      "실제 정답 : ['삭제', '삽입', 'LIFO']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:07,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword          : 삭제\n",
      "detected keyword : 삽입과 삭제는 한\n",
      "keyword          : 삽입\n",
      "detected keyword : 경우 자료의 삽입과\n",
      "keyword          : LIFO\n",
      "detected keyword : 스택의 구조를 후입선출(LIFO,\n",
      "실제 정답 : ['삭제', '삽입', 'LIFO']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:07,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword          : 삭제\n",
      "detected keyword : 삭제 연산을 수행한다.\n",
      "keyword          : 삽입\n",
      "detected keyword : 삽입과 삭제 연산을\n",
      "keyword          : LIFO\n",
      "detected keyword : LIFO(Last In First\n",
      "실제 정답 : ['삭제', '삽입', 'LIFO']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [00:08,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword          : LIFO\n",
      "detected keyword : LIFO(Last-In-First-Out)라는 특징을 가지고\n",
      "실제 정답 : ['삭제', '삽입', 'LIFO']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [00:10,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword          : 삭제\n",
      "detected keyword : 가장 먼저 삭제된다는\n",
      "keyword          : 삽입\n",
      "detected keyword : 통해 삽입하는 연산을\n",
      "keyword          : LIFO\n",
      "detected keyword : 스택 구조를 후입선출(LIFO,\n",
      "실제 정답 : ['삭제', '삽입', 'LIFO']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:12,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword          : 삭제\n",
      "detected keyword : 가장 먼저 삭제된다.\n",
      "keyword          : LIFO\n",
      "detected keyword : LIFO란, 가장 먼저들어온\n",
      "실제 정답 : ['삭제', '삽입', 'LIFO']\n",
      "8번 문제 점수 : accuracy : 0.19886363636363635, f1-score : 0.19924242424242425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:01,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword          : FIFO\n",
      "detected keyword : 선입선출(FIFO) 구조를 가진다.\n",
      "keyword          : 삭제\n",
      "detected keyword : 삭제가 이루어지기 때문에\n",
      "keyword          : 삽입\n",
      "detected keyword : 때문에 먼저 삽입된\n",
      "실제 정답 : ['FIFO', '삭제(POP)', '삽입(PUSH)']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:02,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword          : FIFO\n",
      "detected keyword : FIFO 자료구조. 자료를\n",
      "keyword          : 삭제\n",
      "detected keyword : 추가한다. 자료를 제거\n",
      "실제 정답 : ['FIFO', '삭제(POP)', '삽입(PUSH)']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:03,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword          : FIFO\n",
      "detected keyword : FIFO)의 형태를 가지고\n",
      "keyword          : 삽입\n",
      "detected keyword : 들어가는 것과 같은\n",
      "실제 정답 : ['FIFO']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:04,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword          : 시간복잡도\n",
      "detected keyword : 시간 순서대로 처리해야\n",
      "keyword          : FIFO\n",
      "detected keyword : 나오는 FIFO(First In\n",
      "keyword          : 삽입\n",
      "detected keyword : 먼저 집어 넣은\n",
      "실제 정답 : ['FIFO', '삭제(POP)', '삽입(PUSH)']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:05,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword          : FIFO\n",
      "detected keyword : 큐는 선입선출(FIFO, First\n",
      "keyword          : 삭제\n",
      "detected keyword : 삭제가 이루어집니다. 큐는\n",
      "keyword          : 삽입\n",
      "detected keyword : 삽입과 삭제가 이루어지는\n",
      "실제 정답 : ['FIFO', '삭제(POP)', '삽입(PUSH)']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:05,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword          : 시간복잡도\n",
      "detected keyword : 이루어지는 유한 순서\n",
      "keyword          : FIFO\n",
      "detected keyword : (FIFO) 선입선출이라고 생각하면\n",
      "keyword          : 삭제\n",
      "detected keyword : 먼저 삭제가 된다.\n",
      "keyword          : 삽입\n",
      "detected keyword : 삽입이 이루어지고, 다른\n",
      "실제 정답 : ['FIFO', '삭제(POP)', '삽입(PUSH)']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:06,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword          : FIFO\n",
      "detected keyword : FIFO(First In First\n",
      "실제 정답 : ['FIFO', '삭제(POP)', '삽입(PUSH)']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [00:07,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword          : FIFO\n",
      "detected keyword : 구조로서 선입선출(FIFO :\n",
      "keyword          : 삭제\n",
      "detected keyword : 삭제만 가능한 구조로서\n",
      "keyword          : 삽입\n",
      "detected keyword : 삽입 연산만 가능하고\n",
      "실제 정답 : ['FIFO', '삭제(POP)', '삽입(PUSH)']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [00:07,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword          : FIFO\n",
      "detected keyword : 자료구조.FIFO(First In First\n",
      "실제 정답 : ['FIFO', '삭제(POP)', '삽입(PUSH)']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:08,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword          : FIFO\n",
      "detected keyword : 만 가능. FIFO\n",
      "keyword          : 삭제\n",
      "detected keyword : 끝으로 삭제되는 리스트\n",
      "keyword          : 삽입\n",
      "detected keyword : 삽입되고, 다른 한쪽\n",
      "실제 정답 : ['FIFO', '삭제(POP)', '삽입(PUSH)']\n",
      "9번 문제 점수 : accuracy : 0.17222222222222222, f1-score : 0.17756613756613754\n",
      "전체 문제 평균 accuracy : 0.18773821548821548, f1-score : 0.179527417027417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 유사도 검사 -> Tokenizer 방식에서 띄어쓰기 단위로 2개씩 묶어서 window 방식으로 비교 + 키워드 변형 -> 윈도우 사이즈 3으로 늘림\n",
    "threshold = 0.35\n",
    "total_acc, total_f1 = 0, 0\n",
    "word_concat_size = 3\n",
    "\n",
    "for i, key in enumerate(dataset):\n",
    "    acc, f1 = 0, 0\n",
    "    problem = dataset[key]\n",
    "    for j, (user_answer, ground_truth) in enumerate(tqdm(zip(problem.user_answers, problem.ground_truths))):\n",
    "        if j == 10:\n",
    "            break\n",
    "        split_answer = user_answer.split(' ')\n",
    "        tokenized_answer = []\n",
    "        for k in range(len(split_answer) - word_concat_size + 1):\n",
    "            tokenized_answer.append(' '.join(split_answer[k : k + word_concat_size]))\n",
    "        if len(split_answer) < word_concat_size:\n",
    "            tokenized_answer.append(' '.join(split_answer))\n",
    "        tokenized_answer_embedding = model.encode(tokenized_answer)\n",
    "        similarity_scores = cosine_similarity(problem.keywords_embedding, tokenized_answer_embedding)\n",
    "        predicts = []\n",
    "        for z, idx in enumerate(similarity_scores.argmax(axis=1)):\n",
    "            if threshold < similarity_scores[z][idx]:\n",
    "                print(f\"keyword          : {problem.keywords[z]}\")\n",
    "                print(f\"detected keyword : {tokenized_answer[idx]}\")\n",
    "                predicts.append(1)\n",
    "            else:\n",
    "                predicts.append(0)\n",
    "        print(f\"실제 정답 : {problem.user_correct_keywords[j]}\")\n",
    "        acc += accuracy_score(ground_truth, predicts)\n",
    "        f1 += f1_score(ground_truth, predicts, zero_division=1)\n",
    "    print(f\"{i}번 문제 점수 : accuracy : {acc / len(problem.user_answers)}, f1-score : {f1 / len(problem.user_answers)}\")\n",
    "    total_acc += acc / len(problem.user_answers)\n",
    "    total_f1 += f1 / len(problem.user_answers)\n",
    "print(f\"전체 문제 평균 accuracy : {total_acc / len(dataset)}, f1-score : {total_f1 / len(dataset)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "### 처음에 tokenized 되면서 영어들이 무시되었기 때문에 영어로 구성된 키워드들을 한글로 변형 시켰지만 스윽 보니 이제 영어도 잘 찾네요!!\n",
    "### 그럼 다시 이전 키워드들로 변경해서 성능을 비교해봅시다\n",
    "---"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "outputs": [],
   "source": [
    "dataset['recXfKthnQLwWETgb'].keywords[0] = \"Lifecycle\"  # 만료 -> Lifecycle\n",
    "dataset['recXfKthnQLwWETgb'].keywords_embedding = model.encode(dataset['recXfKthnQLwWETgb'].keywords)  # 1번\n",
    "dataset['recUcGjT9Xkb7N5pu'].keywords[2] = \"삭제(POP)\"  # 삭제 -> 삭제(POP)\n",
    "dataset['recUcGjT9Xkb7N5pu'].keywords[3] = \"삽입(PUSH)\"  # 삽입 -> 삽입(PUSH)\n",
    "dataset['recUcGjT9Xkb7N5pu'].keywords_embedding = model.encode(dataset['recUcGjT9Xkb7N5pu'].keywords)  # 10번\n",
    "dataset['rec1QvAvB4CMami3p'].keywords[2] = 'Stack'  # 스택 -> Stack\n",
    "dataset['rec1QvAvB4CMami3p'].keywords_embedding = model.encode(dataset['rec1QvAvB4CMami3p'].keywords)  # 7번"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45it [00:37,  1.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0번 문제 점수 : accuracy : 0.8944444444444445, f1-score : 0.8392592592592594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45it [00:33,  1.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1번 문제 점수 : accuracy : 0.8148148148148151, f1-score : 0.731851851851852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45it [00:33,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2번 문제 점수 : accuracy : 0.8592592592592594, f1-score : 0.8096296296296297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45it [00:43,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3번 문제 점수 : accuracy : 0.8277777777777777, f1-score : 0.8772486772486771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45it [00:33,  1.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4번 문제 점수 : accuracy : 0.8333333333333334, f1-score : 0.6780952380952382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45it [00:24,  1.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5번 문제 점수 : accuracy : 0.706666666666667, f1-score : 0.45391534391534394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45it [00:26,  1.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6번 문제 점수 : accuracy : 0.9066666666666667, f1-score : 0.8715343915343914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45it [00:21,  2.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7번 문제 점수 : accuracy : 0.8277777777777777, f1-score : 0.7778835978835977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "44it [00:45,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8번 문제 점수 : accuracy : 0.8011363636363636, f1-score : 0.8121212121212121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45it [00:40,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9번 문제 점수 : accuracy : 0.6833333333333333, f1-score : 0.6564021164021167\n",
      "전체 문제 평균 accuracy : 0.8155210437710437, f1-score : 0.7507941317941318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 유사도 검사 -> Tokenizer 방식에서 띄어쓰기 단위로 2개씩 묶어서 window 방식으로 비교 + 키워드 변형 -> 윈도우 사이즈 3으로 늘림\n",
    "threshold = 0.35\n",
    "total_acc, total_f1 = 0, 0\n",
    "word_concat_size = 3\n",
    "\n",
    "for i, key in enumerate(dataset):\n",
    "    acc, f1 = 0, 0\n",
    "    problem = dataset[key]\n",
    "    for j, (user_answer, ground_truth) in enumerate(tqdm(zip(problem.user_answers, problem.ground_truths))):\n",
    "        split_answer = user_answer.split(' ')\n",
    "        tokenized_answer = []\n",
    "        for k in range(len(split_answer) - word_concat_size + 1):\n",
    "            tokenized_answer.append(' '.join(split_answer[k : k + word_concat_size]))\n",
    "        if len(split_answer) < word_concat_size:\n",
    "            tokenized_answer.append(' '.join(split_answer))\n",
    "        tokenized_answer_embedding = model.encode(tokenized_answer)\n",
    "        similarity_scores = cosine_similarity(problem.keywords_embedding, tokenized_answer_embedding)\n",
    "        predicts = [1 if score.max() > threshold else 0 for idx, score in enumerate(similarity_scores)]\n",
    "\n",
    "        acc += accuracy_score(ground_truth, predicts)\n",
    "        f1 += f1_score(ground_truth, predicts, zero_division=1)\n",
    "    print(f\"{i}번 문제 점수 : accuracy : {acc / len(problem.user_answers)}, f1-score : {f1 / len(problem.user_answers)}\")\n",
    "    total_acc += acc / len(problem.user_answers)\n",
    "    total_f1 += f1 / len(problem.user_answers)\n",
    "print(f\"전체 문제 평균 accuracy : {total_acc / len(dataset)}, f1-score : {total_f1 / len(dataset)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "### 1번 문제 : 만료 -> Lifecycle [성능 소폭 하락]\n",
    "### 7번 문제 : 삽입 -> 스택 -> Stack [성능 상승]\n",
    "### 10번 문제 : 삭제 -> 삭제(POP), 삽입 -> 삽입(PUSH) [성능 하락]\n",
    "---"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "### 이번에는 여러개의 키워드라면 쉼표로 구분해서 넣어줘보자\n",
    "---"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "outputs": [],
   "source": [
    "dataset['recXfKthnQLwWETgb'].keywords[0] = \"만료, Lifecycle\"\n",
    "dataset['recXfKthnQLwWETgb'].keywords_embedding = model.encode(dataset['recXfKthnQLwWETgb'].keywords)  # 1번\n",
    "dataset['recUcGjT9Xkb7N5pu'].keywords[2] = \"삭제, POP\"  # 삭제 -> 삭제(POP)\n",
    "dataset['recUcGjT9Xkb7N5pu'].keywords[3] = \"삽입, PUSH\"  # 삽입 -> 삽입(PUSH)\n",
    "dataset['recUcGjT9Xkb7N5pu'].keywords_embedding = model.encode(dataset['recUcGjT9Xkb7N5pu'].keywords)  # 10번\n",
    "dataset['rec1QvAvB4CMami3p'].keywords[2] = 'Stack'  # 스택 -> Stack\n",
    "dataset['rec1QvAvB4CMami3p'].keywords_embedding = model.encode(dataset['rec1QvAvB4CMami3p'].keywords)  # 7번"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45it [00:36,  1.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0번 문제 점수 : accuracy : 0.9222222222222223, f1-score : 0.8977777777777778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45it [00:28,  1.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1번 문제 점수 : accuracy : 0.8148148148148151, f1-score : 0.731851851851852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45it [00:31,  1.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2번 문제 점수 : accuracy : 0.8592592592592594, f1-score : 0.8096296296296297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45it [00:43,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3번 문제 점수 : accuracy : 0.8277777777777777, f1-score : 0.8772486772486771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45it [00:29,  1.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4번 문제 점수 : accuracy : 0.8333333333333334, f1-score : 0.6780952380952382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45it [00:19,  2.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5번 문제 점수 : accuracy : 0.706666666666667, f1-score : 0.45391534391534394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45it [00:25,  1.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6번 문제 점수 : accuracy : 0.9066666666666667, f1-score : 0.8715343915343914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45it [00:19,  2.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7번 문제 점수 : accuracy : 0.8277777777777777, f1-score : 0.7778835978835977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "44it [00:32,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8번 문제 점수 : accuracy : 0.8011363636363636, f1-score : 0.8121212121212121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45it [00:30,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9번 문제 점수 : accuracy : 0.7833333333333333, f1-score : 0.736931216931217\n",
      "전체 문제 평균 accuracy : 0.8282988215488215, f1-score : 0.7646988936988937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 유사도 검사 -> Tokenizer 방식에서 띄어쓰기 단위로 2개씩 묶어서 window 방식으로 비교 + 키워드 변형 -> 윈도우 사이즈 3으로 늘림\n",
    "threshold = 0.35\n",
    "total_acc, total_f1 = 0, 0\n",
    "word_concat_size = 3\n",
    "\n",
    "for i, key in enumerate(dataset):\n",
    "    acc, f1 = 0, 0\n",
    "    problem = dataset[key]\n",
    "    for j, (user_answer, ground_truth) in enumerate(tqdm(zip(problem.user_answers, problem.ground_truths))):\n",
    "        split_answer = user_answer.split(' ')\n",
    "        tokenized_answer = []\n",
    "        for k in range(len(split_answer) - word_concat_size + 1):\n",
    "            tokenized_answer.append(' '.join(split_answer[k : k + word_concat_size]))\n",
    "        if len(split_answer) < word_concat_size:\n",
    "            tokenized_answer.append(' '.join(split_answer))\n",
    "        tokenized_answer_embedding = model.encode(tokenized_answer)\n",
    "        similarity_scores = cosine_similarity(problem.keywords_embedding, tokenized_answer_embedding)\n",
    "        predicts = [1 if score.max() > threshold else 0 for idx, score in enumerate(similarity_scores)]\n",
    "\n",
    "        acc += accuracy_score(ground_truth, predicts)\n",
    "        f1 += f1_score(ground_truth, predicts, zero_division=1)\n",
    "    print(f\"{i}번 문제 점수 : accuracy : {acc / len(problem.user_answers)}, f1-score : {f1 / len(problem.user_answers)}\")\n",
    "    total_acc += acc / len(problem.user_answers)\n",
    "    total_f1 += f1 / len(problem.user_answers)\n",
    "print(f\"전체 문제 평균 accuracy : {total_acc / len(dataset)}, f1-score : {total_f1 / len(dataset)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "### 꽤 유의미한 결과다!!\n",
    "### 마지막으로 word concat size를 2로 줄여서 두개의 단어씩만 비교해보자\n",
    "---"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45it [00:26,  1.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0번 문제 점수 : accuracy : 0.9055555555555556, f1-score : 0.8874074074074073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45it [00:21,  2.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1번 문제 점수 : accuracy : 0.8740740740740741, f1-score : 0.7555555555555555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45it [00:29,  1.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2번 문제 점수 : accuracy : 0.8444444444444444, f1-score : 0.7985185185185186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45it [00:40,  1.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3번 문제 점수 : accuracy : 0.8444444444444444, f1-score : 0.8910052910052908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45it [00:28,  1.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4번 문제 점수 : accuracy : 0.8111111111111111, f1-score : 0.6590476190476191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45it [00:18,  2.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5번 문제 점수 : accuracy : 0.617777777777778, f1-score : 0.38142857142857134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45it [00:22,  2.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6번 문제 점수 : accuracy : 0.8488888888888889, f1-score : 0.7694179894179894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45it [00:18,  2.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7번 문제 점수 : accuracy : 0.8388888888888889, f1-score : 0.8013756613756614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "44it [00:29,  1.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8번 문제 점수 : accuracy : 0.8465909090909091, f1-score : 0.8533549783549783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45it [00:28,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9번 문제 점수 : accuracy : 0.8055555555555556, f1-score : 0.7673015873015873\n",
      "전체 문제 평균 accuracy : 0.8237331649831651, f1-score : 0.7564413179413179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 유사도 검사 -> Tokenizer 방식에서 띄어쓰기 단위로 2개씩 묶어서 window 방식으로 비교 + 키워드 변형 -> 윈도우 사이즈 3으로 늘림\n",
    "threshold = 0.35\n",
    "total_acc, total_f1 = 0, 0\n",
    "word_concat_size = 2\n",
    "\n",
    "for i, key in enumerate(dataset):\n",
    "    acc, f1 = 0, 0\n",
    "    problem = dataset[key]\n",
    "    for j, (user_answer, ground_truth) in enumerate(tqdm(zip(problem.user_answers, problem.ground_truths))):\n",
    "        split_answer = user_answer.split(' ')\n",
    "        tokenized_answer = []\n",
    "        for k in range(len(split_answer) - word_concat_size + 1):\n",
    "            tokenized_answer.append(' '.join(split_answer[k : k + word_concat_size]))\n",
    "        if len(split_answer) < word_concat_size:\n",
    "            tokenized_answer.append(' '.join(split_answer))\n",
    "        tokenized_answer_embedding = model.encode(tokenized_answer)\n",
    "        similarity_scores = cosine_similarity(problem.keywords_embedding, tokenized_answer_embedding)\n",
    "        predicts = [1 if score.max() > threshold else 0 for idx, score in enumerate(similarity_scores)]\n",
    "\n",
    "        acc += accuracy_score(ground_truth, predicts)\n",
    "        f1 += f1_score(ground_truth, predicts, zero_division=1)\n",
    "    print(f\"{i}번 문제 점수 : accuracy : {acc / len(problem.user_answers)}, f1-score : {f1 / len(problem.user_answers)}\")\n",
    "    total_acc += acc / len(problem.user_answers)\n",
    "    total_f1 += f1 / len(problem.user_answers)\n",
    "print(f\"전체 문제 평균 accuracy : {total_acc / len(dataset)}, f1-score : {total_f1 / len(dataset)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "### 전체 정확도는 조금 떨어졌지만 분명 2개씩 봤을 때 성능이 더 좋은 문제들이 있다.\n",
    "### 확실하게 하려면 다음부터는 2개씩 보는 것과 3개씩 보는 것, 그리고 쉼표로 여러 키워드 후보를 비교해보는게 아닌 각각 여러개 비교하기까지 하면 성능이 꽤나 좋아질 것 같다.\n",
    "---"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
